{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  LEVEL\n",
      "0               0.736           0.7700      1\n",
      "1               0.740           0.8000      2\n",
      "2               0.807           0.8125      0\n",
      "3               0.886           0.9250      0\n",
      "4               0.839           0.8550      1\n",
      "..                ...              ...    ...\n",
      "110             0.637           0.6825      2\n",
      "111             0.751           0.8150      2\n",
      "112             0.811           0.8325      1\n",
      "113             0.729           0.7275      2\n",
      "114             0.839           0.8625      1\n",
      "\n",
      "[115 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW2.csv')\n",
    "\n",
    "df=file[['all_mcqs_avg_n20','all_NBME_avg_n4','LEVEL']]\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "#df.fillna(df['STEP_1'].mean(), inplace=True)\n",
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) \n",
    "X= np.array(df.iloc[:,0:2])\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target, test_size=0.30, random_state =0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def  Cost(X_train,theta,y_mapp):\n",
    "    y_pred =  sigmoid(X_train.dot(theta))\n",
    "    cost = np.sum((-y_mapp * np.log(y_pred)) - ((1-y_mapp)*np.log(1-y_pred)))/ len(X_train) \n",
    "    #print('cost',cost)\n",
    "    return cost\n",
    "\n",
    "def Mapping(i,y_train):\n",
    "    ymapped=np.where(y_train == i, 1, 0)\n",
    "    return ymapped\n",
    "\n",
    "def gradient_Descent(X_train,y_train,epochss,alphaa):\n",
    "    theta = []\n",
    "    cost_value=[]\n",
    "    c_t=[]\n",
    "    thetas_inside =  np.random.rand(3,1) \n",
    "    X_train = np.c_[np.ones((len(X_train), 1)), X_train]\n",
    "    # here i in range 4 since we have four class labels\n",
    "    for i in range(4):\n",
    "        y_mapp=Mapping(i,y_train)\n",
    "        cost_each = np.zeros(epochss)\n",
    "        e= 0\n",
    "            \n",
    "        while (e < epochss):\n",
    "\n",
    "            cost_each[i] = Cost(X_train,thetas_inside,y_mapp)\n",
    "            c1=Cost(X_train,thetas_inside,y_mapp)\n",
    "            ynot = sigmoid(np.dot(X_train,(thetas_inside)))\n",
    "            thetas_inside = thetas_inside - ((alphaa / len(X_train)) * np.sum(np.dot(X_train.T,(ynot - y_mapp))))\n",
    "            \n",
    "            c_t.append(c1)  \n",
    "\n",
    "            e+=1\n",
    "            \n",
    "        \n",
    "        theta.append(thetas_inside)\n",
    "        cost_value.append(cost_each)\n",
    "    \n",
    "\n",
    "\n",
    "    return theta,c_t\n",
    "\n",
    "\n",
    "def LogisticRegression( X_train, y_train,epochss,alphaa):\n",
    "\n",
    "    y_train = y_train.to_numpy().reshape(len(X_train),1)\n",
    "    \n",
    "    thetas_pred,c_t=gradient_Descent(X_train,y_train,epochss,alphaa)\n",
    "    return thetas_pred,c_t\n",
    "      \n",
    "        \n",
    "thetas1,c_t=LogisticRegression(X_train,y_train,10000,0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cost_val=[]\n",
    "for i in range(10000):\n",
    "    cost_val.append(c_t[i])\n",
    "    \n",
    "i=list(range (len(cost_val)))\n",
    "plt.xlabel('No of Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(i,cost_val)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    1\n",
       "28    1\n",
       "29    1\n",
       "30    1\n",
       "31    1\n",
       "32    1\n",
       "33    1\n",
       "34    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Predict(X_test,thetas1):\n",
    "    \n",
    "    X = np.c_[np.ones((len(X_test), 1)), X_test]\n",
    "    thetaA=[]\n",
    "    thetaB=[]\n",
    "    thetaC=[]\n",
    "    thetaD=[]\n",
    "    val1_sig=np.matrix(thetas1[0].T)*np.array(X.T)\n",
    "    val1=sigmoid(val1_sig)\n",
    "    val2_sig=np.matrix(thetas1[1].T)*np.array(X.T)\n",
    "    val2=sigmoid(val2_sig)\n",
    "\n",
    "    val3_sig=np.matrix(thetas1[2].T)*np.array(X.T)\n",
    "    val3=sigmoid(val3_sig)\n",
    "    val4_sig=np.matrix(thetas1[3].T)*np.array(X.T)\n",
    "    val4=sigmoid(val4_sig)\n",
    "    val2_df=pd.DataFrame(val2)\n",
    "    val3_df=pd.DataFrame(val3)\n",
    "    val4_df=pd.DataFrame(val4)\n",
    "    belongs_to=pd.DataFrame(val1)\n",
    "\n",
    "\n",
    "    belongs_to=pd.concat([belongs_to,val2_df], ignore_index=True)\n",
    "    belongs_to=pd.concat([belongs_to,val3_df], ignore_index=True)\n",
    "    belongs_to=pd.concat([belongs_to,val4_df], ignore_index=True)\n",
    "\n",
    "    belongs_to_T=belongs_to.T\n",
    "\n",
    "    \n",
    "\n",
    "    values=belongs_to_T.idxmax(axis=1)\n",
    "    return values\n",
    "\n",
    "y_pred=Predict(X_test,thetas1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confuision matrix is :\n",
      "[[ 0  7  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  2  0  0]]\n",
      "The accuracy is  0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.40      1.00      0.57        14\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.40        35\n",
      "   macro avg       0.10      0.25      0.14        35\n",
      "weighted avg       0.16      0.40      0.23        35\n",
      "\n",
      "f1_score 0.14285714285714288\n",
      "precision_score 0.1\n",
      "recall_score 0.25\n"
     ]
    }
   ],
   "source": [
    "print('The confuision matrix is :')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('The accuracy is ',accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print('f1_score',f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, y_pred, average=\"macro\"))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.linear_model import LogisticRegression\\nclf=LogisticRegression(multi_class=\\'multinomial\\', solver=\\'newton-cg\\')\\n\\nclf.fit(X_train, y_train)\\ny_pre=clf.predict(X_test)\\nprint(\\'The confuision matrix is :\\')\\nprint(confusion_matrix(y_test, y_pre))\\nprint(\\'The accuracy is \\',accuracy_score(y_test, y_pre))\\n\\nprint(classification_report(y_test, y_pre))\\n\\nprint(\\'f1_score\\',f1_score(y_test, y_pre, average=\"macro\"))\\nprint(\\'precision_score\\',precision_score(y_test, y_pre, average=\"macro\"))\\nprint(\\'recall_score\\',recall_score(y_test, y_pre, average=\"macro\"))  \\n\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pre=clf.predict(X_test)\n",
    "print('The confuision matrix is :')\n",
    "print(confusion_matrix(y_test, y_pre))\n",
    "print('The accuracy is ',accuracy_score(y_test, y_pre))\n",
    "\n",
    "print(classification_report(y_test, y_pre))\n",
    "\n",
    "print('f1_score',f1_score(y_test, y_pre, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, y_pre, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, y_pre, average=\"macro\"))  \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
