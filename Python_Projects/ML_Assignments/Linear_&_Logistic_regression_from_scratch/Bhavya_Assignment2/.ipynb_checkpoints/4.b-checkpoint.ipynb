{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW2.csv')\n",
    "\n",
    "df=file[['all_mcqs_avg_n20','all_NBME_avg_n4','LEVEL']]\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "#df.fillna(df['STEP_1'].mean(), inplace=True)\n",
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "#print(df) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.837  0.8525]\n",
      " [0.857  0.8725]\n",
      " [0.7    0.6825]\n",
      " [0.798  0.8475]\n",
      " [0.749  0.7925]\n",
      " [0.809  0.8525]\n",
      " [0.778  0.8375]\n",
      " [0.666  0.7475]\n",
      " [0.759  0.81  ]\n",
      " [0.746  0.7625]\n",
      " [0.755  0.77  ]\n",
      " [0.807  0.8125]\n",
      " [0.807  0.88  ]\n",
      " [0.841  0.81  ]\n",
      " [0.762  0.8075]\n",
      " [0.799  0.8125]\n",
      " [0.868  0.895 ]\n",
      " [0.817  0.86  ]\n",
      " [0.728  0.8075]\n",
      " [0.649  0.67  ]\n",
      " [0.769  0.795 ]\n",
      " [0.764  0.79  ]\n",
      " [0.9    0.9125]\n",
      " [0.793  0.86  ]\n",
      " [0.741  0.7175]\n",
      " [0.795  0.8225]\n",
      " [0.637  0.6825]\n",
      " [0.706  0.72  ]\n",
      " [0.682  0.74  ]\n",
      " [0.806  0.82  ]\n",
      " [0.744  0.745 ]\n",
      " [0.91   0.905 ]\n",
      " [0.886  0.925 ]\n",
      " [0.788  0.8   ]\n",
      " [0.679  0.715 ]]\n"
     ]
    }
   ],
   "source": [
    "X= np.array(df.iloc[:,0:2])\n",
    "#X_reg = (X - X.mean())/(X.max()-X.min())\n",
    "#X = np.c_[np.ones((len(X), 1)), X]\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target, test_size=0.30, random_state =0)\n",
    "\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def Mapping(i,y_train):\n",
    "    ymapped=np.where(y_train == i, 1, 0)\n",
    "    return ymapped\n",
    "def  Cost(X_train,theta,y_mapp,lambdaa):\n",
    "    y_pred =  sigmoid(X_train.dot(theta))\n",
    "    cost = np.sum((-y_mapp * np.log(y_pred)) - ((1-y_mapp)*np.log(1-y_pred)))/ len(X_train) \n",
    "    reg_cost= cost + (lambdaa/(2*len(X_train))) * sum(np.square(theta))\n",
    "    return reg_cost\n",
    "\n",
    "def gradient_Descent(X_train,y_train,epochss,alphaa,lambdaa):\n",
    "    \n",
    "    X_train = np.c_[np.ones((len(X_train), 1)), X_train]\n",
    "    theta = []\n",
    "    cost_value=[]\n",
    "    thetas_inside =  np.random.rand(3,1) \n",
    "    # here i in range 4 since we have four class labels\n",
    "    for i in range(4):\n",
    "        \n",
    "        y_mapp=Mapping(i,y_train)\n",
    "        cost_each = np.zeros(epochss)\n",
    "        \n",
    "        e= 0\n",
    "            \n",
    "        while (e < epochss):\n",
    "\n",
    "            cost_each[i] = Cost(X_train,thetas_inside,y_mapp,lambdaa)\n",
    "            ynot = sigmoid(np.dot(X_train,(thetas_inside)))\n",
    "            c1=np.sum(np.dot(X_train.T,(ynot - y_mapp))+(lambdaa * thetas_inside))\n",
    "            thetas_inside = thetas_inside -(alphaa/ len(X_train)) *(c1)\n",
    "            thetas_inside[0] = thetas_inside[0]- (alphaa / len(X_train)) * np.dot(X_train.T,(ynot - y_mapp))[0]\n",
    "            e+=1\n",
    "        theta.append(thetas_inside)\n",
    "        cost_value.append(cost_each)\n",
    "\n",
    "\n",
    "    return theta\n",
    "\n",
    "\n",
    "\n",
    "def LogisticRegression( X_train, y_train,epochss,alphaa,lambdaa):\n",
    "\n",
    "    y_train = y_train.to_numpy().reshape(len(X_train),1)\n",
    "    thetas_pred=gradient_Descent(X_train,y_train,epochss,alphaa,lambdaa)\n",
    "    return thetas_pred\n",
    "      \n",
    "        \n",
    "thetas1=LogisticRegression(X_train,y_train,10000,0.1,0.001)\n",
    "thetas2=LogisticRegression(X_train,y_train,10000,0.1,3.0)\n",
    "thetas3=LogisticRegression(X_train,y_train,10000,0.1,6.0)\n",
    "thetas4=LogisticRegression(X_train,y_train,10000,0.1,7.8)\n",
    "thetas5=LogisticRegression(X_train,y_train,10000,0.1,9.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X_test,thetas1):\n",
    "    \n",
    "    X = np.c_[np.ones((len(X_test), 1)), X_test]\n",
    "    thetaA=[]\n",
    "    thetaB=[]\n",
    "    thetaC=[]\n",
    "    thetaD=[]\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    val1_sig=np.matrix(thetas1[0].T)*np.array(X.T)\n",
    "    val1=sigmoid(val1_sig)\n",
    "    val2_sig=np.matrix(thetas1[1].T)*np.array(X.T)\n",
    "    val2=sigmoid(val2_sig)\n",
    "\n",
    "    val3_sig=np.matrix(thetas1[2].T)*np.array(X.T)\n",
    "    val3=sigmoid(val3_sig)\n",
    "    val4_sig=np.matrix(thetas1[3].T)*np.array(X.T)\n",
    "    val4=sigmoid(val4_sig)\n",
    "    val2_df=pd.DataFrame(val2)\n",
    "    val3_df=pd.DataFrame(val3)\n",
    "    val4_df=pd.DataFrame(val4)\n",
    "    belongs_to=pd.DataFrame(val1)\n",
    "\n",
    "\n",
    "    belongs_to=pd.concat([belongs_to,val2_df], ignore_index=True)\n",
    "    belongs_to=pd.concat([belongs_to,val3_df], ignore_index=True)\n",
    "    belongs_to=pd.concat([belongs_to,val4_df], ignore_index=True)\n",
    "\n",
    "    belongs_to_T=belongs_to.T\n",
    "\n",
    "    \n",
    "\n",
    "    values=belongs_to_T.idxmax(axis=1)\n",
    "    return values\n",
    "\n",
    "values1=Predict(X_test,thetas1)\n",
    "values2=Predict(X_test,thetas2)\n",
    "values3=Predict(X_test,thetas3)\n",
    "values4=Predict(X_test,thetas4)\n",
    "values5=Predict(X_test,thetas5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for lambda = 0.001, alpha =10000,learning rate=0.1  0.45714285714285713\n",
      "The accuracy score for lambda = 3, alpha =10000,learning rate=0.1 0.42857142857142855\n",
      "The accuracy score for lambda = 6, alpha =10000,learning rate=0.1 0.4\n",
      "The accuracy score for lambda = 7.8, alpha =10000,learning rate=0.1 0.4\n",
      "The accuracy score for lambda = 9.9, alpha =10000,learning rate=0.1 0.4\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy score for lambda = 0.001, alpha =10000,learning rate=0.1 ',accuracy_score(y_test, values1))\n",
    "print('The accuracy score for lambda = 3, alpha =10000,learning rate=0.1',accuracy_score(y_test, values2))\n",
    "print('The accuracy score for lambda = 6, alpha =10000,learning rate=0.1',accuracy_score(y_test, values3))\n",
    "print('The accuracy score for lambda = 7.8, alpha =10000,learning rate=0.1',accuracy_score(y_test, values4))\n",
    "print('The accuracy score for lambda = 9.9, alpha =10000,learning rate=0.1',accuracy_score(y_test, values5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 0.001, alpha =10000,learning rate=0.1\n",
      "confusion_matrix\n",
      "[[ 0  7  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 10  2  0]\n",
      " [ 0  2  0  0]]\n",
      "accuracy_score 0.45714285714285713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.42      1.00      0.60        14\n",
      "           2       1.00      0.17      0.29        12\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.46      0.46      0.46        35\n",
      "   macro avg       0.36      0.29      0.22        35\n",
      "weighted avg       0.51      0.46      0.34        35\n",
      "\n",
      "f1_score 0.22036474164133737\n",
      "precision_score 0.3560606060606061\n",
      "recall_score 0.2916666666666667\n"
     ]
    }
   ],
   "source": [
    "print('For lambda = 0.001, alpha =10000,learning rate=0.1')\n",
    "print('confusion_matrix')\n",
    "print(confusion_matrix(y_test, values1))\n",
    "print('accuracy_score',accuracy_score(y_test, values1))\n",
    "print(classification_report(y_test, values1))\n",
    "print('f1_score',f1_score(y_test, values1, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, values1, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, values1, average=\"macro\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 3, alpha =10000,learning rate=0.1\n",
      "confusion_matrix\n",
      "[[ 2  5  0  0]\n",
      " [ 1 13  0  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  2  0  0]]\n",
      "accuracy_score 0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40         7\n",
      "           1       0.41      0.93      0.57        14\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.43      0.43      0.43        35\n",
      "   macro avg       0.27      0.30      0.24        35\n",
      "weighted avg       0.30      0.43      0.31        35\n",
      "\n",
      "f1_score 0.24130434782608695\n",
      "precision_score 0.26822916666666663\n",
      "recall_score 0.3035714285714286\n"
     ]
    }
   ],
   "source": [
    "print('For lambda = 3, alpha =10000,learning rate=0.1')\n",
    "print('confusion_matrix')\n",
    "print(confusion_matrix(y_test, values2))\n",
    "print('accuracy_score',accuracy_score(y_test, values2))\n",
    "print(classification_report(y_test, values2))\n",
    "print('f1_score',f1_score(y_test, values2, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, values2, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, values2, average=\"macro\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 6.0, alpha =10000,learning rate=0.1\n",
      "confusion_matrix\n",
      "[[ 0  7  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  2  0  0]]\n",
      "accuracy_score 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.40      1.00      0.57        14\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        35\n",
      "   macro avg       0.10      0.25      0.14        35\n",
      "weighted avg       0.16      0.40      0.23        35\n",
      "\n",
      "f1_score 0.14285714285714288\n",
      "precision_score 0.1\n",
      "recall_score 0.25\n"
     ]
    }
   ],
   "source": [
    "print('For lambda = 6.0, alpha =10000,learning rate=0.1')\n",
    "print('confusion_matrix')\n",
    "print(confusion_matrix(y_test, values3))\n",
    "print('accuracy_score',accuracy_score(y_test, values3))\n",
    "print(classification_report(y_test, values3))\n",
    "print('f1_score',f1_score(y_test, values3, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, values3, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, values3, average=\"macro\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 7.8, alpha =10000,learning rate=0.1\n",
      "confusion_matrix\n",
      "[[ 0  7  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  2  0  0]]\n",
      "accuracy_score 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.40      1.00      0.57        14\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        35\n",
      "   macro avg       0.10      0.25      0.14        35\n",
      "weighted avg       0.16      0.40      0.23        35\n",
      "\n",
      "f1_score 0.14285714285714288\n",
      "precision_score 0.1\n",
      "recall_score 0.25\n"
     ]
    }
   ],
   "source": [
    "print('For lambda = 7.8, alpha =10000,learning rate=0.1')\n",
    "print('confusion_matrix')\n",
    "print(confusion_matrix(y_test, values4))\n",
    "print('accuracy_score',accuracy_score(y_test, values4))\n",
    "print(classification_report(y_test, values4))\n",
    "print('f1_score',f1_score(y_test, values4, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, values4, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, values4, average=\"macro\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lambda = 9.9, alpha =10000,learning rate=0.1\n",
      "confusion_matrix\n",
      "[[ 0  7  0  0]\n",
      " [ 0 14  0  0]\n",
      " [ 0 12  0  0]\n",
      " [ 0  2  0  0]]\n",
      "accuracy_score 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.40      1.00      0.57        14\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.40      0.40      0.40        35\n",
      "   macro avg       0.10      0.25      0.14        35\n",
      "weighted avg       0.16      0.40      0.23        35\n",
      "\n",
      "f1_score 0.14285714285714288\n",
      "precision_score 0.1\n",
      "recall_score 0.25\n"
     ]
    }
   ],
   "source": [
    "print('For lambda = 9.9, alpha =10000,learning rate=0.1')\n",
    "print('confusion_matrix')\n",
    "print(confusion_matrix(y_test, values5))\n",
    "print('accuracy_score',accuracy_score(y_test, values5))\n",
    "print(classification_report(y_test, values5))\n",
    "print('f1_score',f1_score(y_test, values5, average=\"macro\"))\n",
    "print('precision_score',precision_score(y_test, values5, average=\"macro\"))\n",
    "print('recall_score',recall_score(y_test, values5, average=\"macro\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
