{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import csv \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#print('',)\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 . Adding a column 'all_NBME_avg_n4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4244: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  **kwargs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "STEP_1              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW2.csv')\n",
    "\n",
    "df=file[['all_mcqs_avg_n20','all_NBME_avg_n4','STEP_1']]\n",
    "\n",
    "df.isnull().any()\n",
    "\n",
    "df.fillna(df['STEP_1'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 2)\n",
      "(115,)\n"
     ]
    }
   ],
   "source": [
    "# seperating the data into independedent variables and target varibles\n",
    "\n",
    "\n",
    "\n",
    "X = df.iloc[:, :-1]  # values converts it into a numpy array\n",
    "\n",
    "target=df.iloc[:, -1]  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 2)\n",
      "(23, 2)\n",
      "(92,)\n",
      "(23,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target, test_size=0.20)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef gradientDescent(X, y,theta2, theta1, theta0,epochs,learning_rate):\\n    N = float(len(y))\\n    th1=[]\\n    th0=[]\\n    th2=[]\\n    cost_all=[]\\n    for i in range(epochs):\\n        y_current = (theta2 * X.iloc[:,1])+(theta1 * X.iloc[:,0]) + theta0\\n          \\n        cost = sum([data**2 for data in (y-y_current)]) / (2*N)\\n        cost_all.append(cost)\\n          \\n        m_gradient = -(2/N) * sum(X * (y - y_current))\\n        b_gradient = -(2/N) * sum(y - y_current)\\n        \\n        theta2= theta2 - (learning_rate * m_gradient)\\n        th2.append(theta2)\\n        \\n        theta1 = theta1 - (learning_rate * m_gradient)\\n        th1.append(theta1)\\n         \\n        theta0 = theta0 - (learning_rate * b_gradient)\\n        th0.append(theta0)\\n            \\n     \\n          \\n    return theta2,theta1,theta0,cost_all,y_current\\n\\ntheta_2,theta_1,theta_0,costAll,y_current1 =gradientDescent(X_train,y_train,0,0,0,200,0.01)\\n\\nprint(theta_2)\\nprint(theta_1)\\nprint(theta_0)\\n#print(costAll)\\n\\n\\nmyarray = np.asarray(costAll)\\n\\nprint(myarray)\\ni=np.arange(len(myarray))\\n\\nprint(i)\\nplt.scatter(i,myarray)\\nplt.plot(i,myarray)\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "def gradientDescent(X, y,theta2, theta1, theta0,epochs,learning_rate):\n",
    "    N = float(len(y))\n",
    "    th1=[]\n",
    "    th0=[]\n",
    "    th2=[]\n",
    "    cost_all=[]\n",
    "    for i in range(epochs):\n",
    "        y_current = (theta2 * X.iloc[:,1])+(theta1 * X.iloc[:,0]) + theta0\n",
    "          \n",
    "        cost = sum([data**2 for data in (y-y_current)]) / (2*N)\n",
    "        cost_all.append(cost)\n",
    "          \n",
    "        m_gradient = -(2/N) * sum(X * (y - y_current))\n",
    "        b_gradient = -(2/N) * sum(y - y_current)\n",
    "        \n",
    "        theta2= theta2 - (learning_rate * m_gradient)\n",
    "        th2.append(theta2)\n",
    "        \n",
    "        theta1 = theta1 - (learning_rate * m_gradient)\n",
    "        th1.append(theta1)\n",
    "         \n",
    "        theta0 = theta0 - (learning_rate * b_gradient)\n",
    "        th0.append(theta0)\n",
    "            \n",
    "     \n",
    "          \n",
    "    return theta2,theta1,theta0,cost_all,y_current\n",
    "\n",
    "theta_2,theta_1,theta_0,costAll,y_current1 =gradientDescent(X_train,y_train,0,0,0,200,0.01)\n",
    "\n",
    "print(theta_2)\n",
    "print(theta_1)\n",
    "print(theta_0)\n",
    "#print(costAll)\n",
    "\n",
    "\n",
    "myarray = np.asarray(costAll)\n",
    "\n",
    "print(myarray)\n",
    "i=np.arange(len(myarray))\n",
    "\n",
    "print(i)\n",
    "plt.scatter(i,myarray)\n",
    "plt.plot(i,myarray)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, Y, B):\n",
    "    m = len(Y)\n",
    "    J = np.sum((X.dot(B)-Y) ** 2)/(2 * m)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, Y, B, alpha, iterations):\n",
    "    cost_history = [0] * iterations\n",
    "    m = len(Y)\n",
    "    for iteration in range(iterations):\n",
    " \n",
    " # Hypothesis Values\n",
    "        h = X.dot(B)\n",
    " # Difference b/w Hypothesis and Actual Y\n",
    "        loss = h-Y\n",
    " # Gradient Calculation\n",
    "        gradient = X.T.dot(loss) / m\n",
    " # Changing Values of B using Gradient\n",
    "        B = B-alpha * gradient\n",
    " # New Cost Value\n",
    "        cost = cost_function(X, Y, B)\n",
    "        cost_history[iteration] = cost\n",
    " \n",
    "    return B,cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.c_[np.ones(len(X_train),dtype='int64'),X_train]\n",
    "\n",
    "X_test = np.c_[np.ones(len(X_test),dtype='int64'),X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Coefficients\n",
    "B = np.zeros(X_train.shape[1])\n",
    "alpha = 0.01\n",
    "iter_ = 1000\n",
    "newB,cost_history = batch_gradient_descent(X_train, y_train, B, alpha, iter_)\n",
    "\n",
    "#print(newB,cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=list(range (len(cost_history)))\n",
    "#print(i)\n",
    "plt.plot(i,cost_history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "y_ =np.sum(X_test*newB , axis=1)\n",
    "\n",
    "y_pred=pd.Series(y_)\n",
    "print(type(y_pred))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is : 14.751614244022818\n",
      "0.9411015293287237\n"
     ]
    }
   ],
   "source": [
    "def mse(y_true,y_Pred):\n",
    "    mse=1/len(y_true)*np.sum(np.subtract(y_true,y_Pred)**2)\n",
    "    \n",
    "    return mse\n",
    "def r_square(y_true,y_Pred):\n",
    "   # y -ypred whole square \n",
    "    #y- mean of y whole square \n",
    "    r2= 1- (np.sum(np.subtract(y_true,y_Pred)**2)/np.sum(np.subtract(y_true,np.mean(y_true))**2))\n",
    "    return r2\n",
    "    \n",
    "    \n",
    "mse_cal=mse(y_test, y_pred)\n",
    "#mse1=mse(y_test, y_pred_o)\n",
    "print('MSE is :',mse_cal)\n",
    "\n",
    "#print('MSE1 is :',mse1)\n",
    "\n",
    "r_2=r_square(y_test, y_pred)\n",
    "\n",
    "print(r_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.48263788359313"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pre=reg.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
