{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    0\n",
       "all_NBME_avg_n4     0\n",
       "CBSE_01             0\n",
       "CBSE_02             0\n",
       "LEVEL               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW2.csv')\n",
    "\n",
    "df=file[['all_mcqs_avg_n20','all_NBME_avg_n4','CBSE_01','CBSE_02','LEVEL']]\n",
    "\n",
    "df['CBSE_02'].fillna(df['CBSE_02'].mean(),inplace=True)\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "#df.fillna(df['STEP_1'].mean(), inplace=True)\n",
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "#print(df) \n",
    "\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with out feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(df.iloc[:,0:4])\n",
    "\n",
    "#X = np.c_[np.ones((len(X), 1)), X]\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,target, test_size=0.20, random_state =0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4   CBSE_01  CBSE_02\n",
      "0            0.420000            0.496  0.257143     0.44\n",
      "1            0.433333            0.592  0.314286     0.42\n",
      "2            0.656667            0.632  0.228571     0.64\n",
      "3            0.920000            0.992  1.000000     0.90\n",
      "4            0.763333            0.768  0.685714     0.56\n",
      "..                ...              ...       ...      ...\n",
      "110          0.090000            0.216  0.342857     0.12\n",
      "111          0.470000            0.640  0.571429     0.28\n",
      "112          0.670000            0.696  0.485714     0.62\n",
      "113          0.396667            0.360  0.285714     0.44\n",
      "114          0.763333            0.792  0.600000     0.54\n",
      "\n",
      "[115 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df2=df.iloc[:,:-1]\n",
    "#print(df2)\n",
    "df_FS=(df2-df2.min())/(df2.max()-df2.min())\n",
    "print(df_FS)\n",
    "X1= np.array(df_FS)\n",
    "target=df.iloc[:,-1]\n",
    "X_train_FS, X_test_FS, y_train_FS, y_test_FS = train_test_split(X1,target, test_size=0.20, random_state =0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def  Cost(X_train,theta,y_mapp,lambdaa):\n",
    "    y_pred =  sigmoid(X_train.dot(theta))\n",
    "    error = (-y_mapp * np.log(y_pred)) - ((1-y_mapp)*np.log(1-y_pred))    \n",
    "    cost = 1/len(X_train) * sum(error)   \n",
    "    reg_cost= cost + lambdaa/(len(X_train)) * sum(abs(theta))\n",
    "    return reg_cost\n",
    "\n",
    "def gradient_Descent(X_train,y_train,epochs,alpha,lambdaa):\n",
    "    \n",
    "    X_train = np.c_[np.ones((len(X_train), 1)), X_train]\n",
    "    theta = []\n",
    "    cost_value=[]\n",
    "    thetas_inside =  np.random.rand(5,1) \n",
    "    # here i in range 4 since we have four class labels\n",
    "    for i in range(4):\n",
    "        cost_each = np.zeros(epochs)\n",
    "        y_mapp = np.where(y_train == i, 1, 0)\n",
    "        \n",
    "        e = 0\n",
    "            \n",
    "        while (e < epochs):\n",
    "\n",
    "            cost_each[i] = Cost(X_train,thetas_inside,y_mapp,lambdaa)\n",
    "            pred = 1/(1+np.exp(-X_train.dot(thetas_inside)))\n",
    "            thetas_inside = thetas_inside - (alpha *((1/ len(X_train)) * (X_train.T).dot(pred - y_mapp)+(thetas_inside*(lambdaa/len(X_train)))))\n",
    "            \n",
    "            #thetas_inside[0] = thetas_inside[0]- ((alpha /len(X_train) * (X_train.T).dot(pred - y_mapp)[0])\n",
    "            e = e + 1\n",
    "        theta.append(thetas_inside)\n",
    "        cost_value.append(cost_each)\n",
    "\n",
    "\n",
    "    return theta\n",
    "\n",
    "\n",
    "def LogisticRegression( X_train, y_train,epochs,alpha,lambdaa):\n",
    "\n",
    "    \n",
    "    numberOfClasses = len(np.unique(y_train))\n",
    "    y_train = y_train.to_numpy().reshape(len(X_train),1)\n",
    "    thetas_pred=gradient_Descent(X_train,y_train,epochs,alpha,lambdaa)\n",
    "    return thetas_pred\n",
    "      \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(X_test,thetas1):\n",
    "    \n",
    "    X = np.c_[np.ones((len(X_test), 1)), X_test]\n",
    "    thetaA=[]\n",
    "    thetaB=[]\n",
    "    thetaC=[]\n",
    "    thetaD=[]\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    val1_sig=np.matrix(thetas1[0].T)*np.array(X.T)\n",
    "    val1=sigmoid(val1_sig)\n",
    "    val2_sig=np.matrix(thetas1[1].T)*np.array(X.T)\n",
    "    val2=sigmoid(val2_sig)\n",
    "\n",
    "    val3_sig=np.matrix(thetas1[2].T)*np.array(X.T)\n",
    "    val3=sigmoid(val3_sig)\n",
    "    val4_sig=np.matrix(thetas1[3].T)*np.array(X.T)\n",
    "    val4=sigmoid(val4_sig)\n",
    "    val2_df=pd.DataFrame(val2)\n",
    "    val3_df=pd.DataFrame(val3)\n",
    "    val4_df=pd.DataFrame(val4)\n",
    "    belongs_to=pd.DataFrame(val1)\n",
    "\n",
    "\n",
    "    belongs_to=pd.concat([belongs_to,val2_df], ignore_index=True)\n",
    "    belongs_to=pd.concat([belongs_to,val3_df], ignore_index=True)\n",
    "    belongs_to=pd.concat([belongs_to,val4_df], ignore_index=True)\n",
    "\n",
    "    belongs_to_T=belongs_to.T\n",
    "\n",
    "    \n",
    "\n",
    "    values=belongs_to_T.idxmax(axis=1)\n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thetas Before feature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  import sys\n",
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in multiply\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3\n",
      "1     0\n",
      "2     3\n",
      "3     3\n",
      "4     0\n",
      "5     0\n",
      "6     3\n",
      "7     3\n",
      "8     3\n",
      "9     3\n",
      "10    3\n",
      "11    0\n",
      "12    3\n",
      "13    3\n",
      "14    0\n",
      "15    3\n",
      "16    0\n",
      "17    3\n",
      "18    3\n",
      "19    3\n",
      "20    3\n",
      "21    3\n",
      "22    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "thetas1=LogisticRegression(X_train,y_train,1000,0.01,0.5)\n",
    "\n",
    "thetas2=LogisticRegression(X_train,y_train,1000,0.01,2.5)\n",
    "thetas3=LogisticRegression(X_train,y_train,1000,0.01,3.5)\n",
    "thetas4=LogisticRegression(X_train,y_train,1000,0.01,4)\n",
    "thetas5=LogisticRegression(X_train,y_train,1000,0.01,5.5)\n",
    "thetas6=LogisticRegression(X_train,y_train,1000,0.01,6.5)\n",
    "thetas7=LogisticRegression(X_train,y_train,1000,0.01,7)\n",
    "thetas8=LogisticRegression(X_train,y_train,1000,0.01,8.5)\n",
    "thetas9=LogisticRegression(X_train,y_train,1000,0.01,9.5)\n",
    "\n",
    "y_pred1=Predict(X_test,thetas1)\n",
    "y_pred2=Predict(X_test,thetas2)\n",
    "y_pred3=Predict(X_test,thetas3)\n",
    "y_pred4=Predict(X_test,thetas4)\n",
    "y_pred5=Predict(X_test,thetas5)\n",
    "y_pred6=Predict(X_test,thetas6)\n",
    "y_pred7=Predict(X_test,thetas7)\n",
    "y_pred8=Predict(X_test,thetas8)\n",
    "y_pred9=Predict(X_test,thetas9)\n",
    "print(y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2608695652173913\n",
      "0.08695652173913043\n",
      "0.21739130434782608\n",
      "0.21739130434782608\n",
      "0.2608695652173913\n",
      "0.08695652173913043\n",
      "0.2608695652173913\n",
      "0.5217391304347826\n",
      "0.043478260869565216\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred1))\n",
    "print(accuracy_score(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred3))\n",
    "print(accuracy_score(y_test, y_pred4))\n",
    "print(accuracy_score(y_test, y_pred5))\n",
    "print(accuracy_score(y_test, y_pred6))\n",
    "print(accuracy_score(y_test, y_pred7))\n",
    "print(accuracy_score(y_test, y_pred8))\n",
    "print(accuracy_score(y_test, y_pred9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thetas after feature scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3\n",
      "1     0\n",
      "2     3\n",
      "3     3\n",
      "4     0\n",
      "5     0\n",
      "6     3\n",
      "7     3\n",
      "8     3\n",
      "9     3\n",
      "10    3\n",
      "11    0\n",
      "12    3\n",
      "13    3\n",
      "14    0\n",
      "15    3\n",
      "16    0\n",
      "17    3\n",
      "18    3\n",
      "19    3\n",
      "20    3\n",
      "21    3\n",
      "22    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "thetas1_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,0.5)\n",
    "thetas2_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,2.5)\n",
    "thetas3_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,3.5)\n",
    "thetas4_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,4)\n",
    "thetas5_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,5.5)\n",
    "thetas6_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,6.5)\n",
    "thetas7_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,7)\n",
    "thetas8_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,8.5)\n",
    "thetas9_FS=LogisticRegression(X_train_FS,y_train_FS,1000,0.01,9.5)\n",
    "\n",
    "y_pred_FS1=Predict(X_test,thetas1)\n",
    "y_pred_FS2=Predict(X_test,thetas2)\n",
    "y_pred_FS3=Predict(X_test,thetas3)\n",
    "y_pred_FS4=Predict(X_test,thetas4)\n",
    "y_pred_FS5=Predict(X_test,thetas5)\n",
    "y_pred_FS6=Predict(X_test,thetas6)\n",
    "y_pred_FS7=Predict(X_test,thetas7)\n",
    "y_pred_FS8=Predict(X_test,thetas8)\n",
    "y_pred_FS9=Predict(X_test,thetas9)\n",
    "print(y_pred_FS1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2608695652173913\n",
      "0.08695652173913043\n",
      "0.21739130434782608\n",
      "0.21739130434782608\n",
      "0.2608695652173913\n",
      "0.08695652173913043\n",
      "0.2608695652173913\n",
      "0.5217391304347826\n",
      "0.043478260869565216\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_FS, y_pred_FS1))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS2))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS3))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS4))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS5))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS6))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS7))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS8))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0 0]\n",
      " [5 7 0 0]\n",
      " [1 3 1 0]\n",
      " [0 1 1 0]]\n",
      "0.5217391304347826\n",
      "[[ 0  0  4  0]\n",
      " [ 0  0 12  0]\n",
      " [ 0  0  5  0]\n",
      " [ 0  0  2  0]]\n",
      "0.21739130434782608\n",
      "[[ 4  0  0  0]\n",
      " [ 2  0  0 10]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0  2]]\n",
      "0.2608695652173913\n",
      "[[ 4  0  0  0]\n",
      " [ 2  0  0 10]\n",
      " [ 0  0  0  5]\n",
      " [ 0  0  0  2]]\n",
      "0.2608695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Bhavya N\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25263157894736843"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pre_sk=clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pre_sk))\n",
    "print(accuracy_score(y_test, y_pre_sk))\n",
    "\n",
    "y_pre_fs=clf.predict(X_test_FS)\n",
    "print(confusion_matrix(y_test_FS, y_pre_fs))\n",
    "print(accuracy_score(y_test_FS, y_pre_fs))\n",
    "\n",
    "\n",
    "############  for with out fs\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred1))\n",
    "print(accuracy_score(y_test, y_pred1))\n",
    "#print('y_pred1',y_pred1)\n",
    "\n",
    "############ with out fs\n",
    "\n",
    "print(confusion_matrix(y_test_FS, y_pred_FS1))\n",
    "print(accuracy_score(y_test_FS, y_pred_FS1))\n",
    "from sklearn.metrics import f1_score\n",
    "f1=f1_score(y_test_FS, y_pred_FS1, average='macro')  \n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.96560287, -0.98853912, -0.04041056,  0.07449414],\n",
       "       [ 0.59527018,  0.59066635, -0.03378775, -0.0034075 ],\n",
       "       [ 0.08403637,  0.13514899,  0.05717744, -0.07676314],\n",
       "       [ 0.18619455,  0.14016263,  0.07222566, -0.11074146]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
