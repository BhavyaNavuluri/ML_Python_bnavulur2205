{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "CBSE_01             False\n",
       "CBSE_02             False\n",
       "LEVEL               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "\n",
    "\n",
    "# to check whether there are any empty values or not \n",
    "df=file[['all_mcqs_avg_n20', 'all_NBME_avg_n4', 'CBSE_01',  'CBSE_02', 'LEVEL']]\n",
    "\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "df[['CBSE_02']].fillna(method ='bfill')\n",
    "#.fillna(52, inplace=True)\n",
    "df.fillna(df['CBSE_02'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  CBSE_01  CBSE_02  LEVEL\n",
      "0               0.736           0.7700       42     68.0      1\n",
      "1               0.740           0.8000       44     67.0      2\n",
      "2               0.807           0.8125       41     78.0      0\n",
      "3               0.886           0.9250       68     91.0      0\n",
      "4               0.839           0.8550       57     74.0      1\n",
      "..                ...              ...      ...      ...    ...\n",
      "110             0.637           0.6825       45     52.0      2\n",
      "111             0.751           0.8150       53     60.0      2\n",
      "112             0.811           0.8325       50     77.0      1\n",
      "113             0.729           0.7275       43     68.0      2\n",
      "114             0.839           0.8625       54     73.0      1\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mapping LEVEL column to 0 ,1,2,3 \n",
    "\n",
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming y to binary number using one-hot- encoding\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#onhtencder = OneHotEncoder(categorical_features = [0]) \n",
    "\n",
    "onhtencder= ColumnTransformer([(\"LEVEL\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "\n",
    "\n",
    "data = onhtencder.fit_transform(df[['LEVEL']]).toarray() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df.iloc[:,:]\n",
    "\n",
    "#Normalizing the data \n",
    "\n",
    "X_norm = (X.iloc[:,:-1] - X.iloc[:,:-1].mean()) / (X.iloc[:,:-1].max() - X.iloc[:,:-1].min())\n",
    "\n",
    "\n",
    "\n",
    "X_modified = pd.concat([X_norm, X.iloc[:,-1]],axis=1)\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "\n",
    "#Train test split \n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X_modified, data, test_size=0.20,random_state=9)\n",
    "\n",
    "\n",
    "Train_ip=np.array(XTrain.iloc[:,:-1])\n",
    "Train_otpts=np.array(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(22)\n",
    "\n",
    "wt1 = np.random.random((5,5))    \n",
    "wt2 = np.random.random((4,6))    \n",
    "ttl_weits = np.hstack((wt1.ravel(order='F'), wt2.ravel(order='F')))    #unrolling the  params\n",
    "\n",
    "# layers configuration \n",
    "\n",
    "ip_lyr = 4\n",
    "hd_lyr = 5\n",
    "no_labls = 4\n",
    "\n",
    "#print('wt1',wt1)\n",
    "#print('wt2',wt2)\n",
    "#print('ttl_weits',ttl_weits)\n",
    "#print(ttl_weits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(ttl_weits,ip,hidn,otpt):\n",
    "    w1 = np.reshape(ttl_weits[:hidn*(ip+1)], (hidn, ip+1), 'F')\n",
    "    w2 = np.reshape(ttl_weits[hidn*(ip+1):], (otpt, hidn+1), 'F')\n",
    "    return w1,w2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIG(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def SIGGrad(z):\n",
    "    return np.multiply(SIG(z), 1-SIG(z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(h,y):\n",
    "    cost = np.sum(np.multiply(y, np.log(h))+np.multiply(1-y, np.log(1-h)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward_propagation \n",
    "\n",
    "def Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip, Train_otpts):\n",
    "    \n",
    "    wt1,wt2= Weights(ttl_weits, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "   \n",
    "    l = len(Train_ip)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    #print('ones',ones)\n",
    "    a_1 = np.hstack((ones, Train_ip))\n",
    "    #print('a_1',a_1)\n",
    "    a_2 = SIG(a_1 @ wt1.T)\n",
    "    #print('a_2',a_2)\n",
    "    a_2 = np.hstack((ones, a_2))\n",
    "    #print('a_2',a_2)\n",
    "    h = SIG(a_2 @ wt2.T)\n",
    "    #print('h',h)\n",
    "    \n",
    "    c=Cost(h,Train_otpts)\n",
    "\n",
    "   \n",
    "    \n",
    "    return c / (-l)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_er = Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip,Train_otpts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def NN(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip,Train_otpts):\n",
    "    \n",
    "    \n",
    "    initt_wt1,initt_wt2= Weights(ttl_weits, ip_lyr, hd_lyr, no_labls)\n",
    "    \n",
    "   \n",
    "    lenth = len(Train_otpts)\n",
    "\n",
    "    ones = np.ones((lenth,1))\n",
    "    # Farward Prop\n",
    "    \n",
    "    a_1 = np.hstack((ones, Train_ip))\n",
    "    #print('a_1',a_1)\n",
    "    #print('a_1 shape',a_1.shape)\n",
    "    z_2 = a_1 @ initt_wt1.T\n",
    "    #print('z_2',z_2)\n",
    "    #print('z_2 sha',z_2.shape)\n",
    "    a_2 = np.hstack((ones, SIG(z_2)))\n",
    "    #print('a_2 ',a_2)\n",
    "    #print('a_2 ',a_2.shape)\n",
    "    z_3 = a_2 @ initt_wt2.T\n",
    "    #print('z_3',z_3)\n",
    "    #print('z_3 ',z_3.shape)\n",
    "    a_3 = SIG(z_3)\n",
    "    #print('a_3',a_3)\n",
    "    #print('a_3',a_3.shape)\n",
    "    \n",
    "    \n",
    "    #Backword_propagation\n",
    "\n",
    "    d_3 = a_3 - Train_otpts\n",
    "    #print('d_3',d_3)\n",
    "    #print('d_3',d_3.shape)\n",
    "    z_2 = np.hstack((ones, z_2))\n",
    "    #print('z_2',z_2)\n",
    "    #print('z_2',z_2.shape)\n",
    "    d_2 = np.multiply(initt_wt2.T @ d_3.T, SIGGrad(z_2).T)\n",
    "    #print('d_2',d_2)\n",
    "    #print('d_2',d_2.shape)\n",
    "    \n",
    "    delta1 = np.zeros(initt_wt1.shape)\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1 shape',delta1.shape)\n",
    "    delta2 = np.zeros(initt_wt2.shape)\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 shape',delta2.shape)\n",
    "    \n",
    "    delta1 = delta1 + d_2[1:,:] @ a_1\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1',delta1.shape)\n",
    "    delta2 = delta2 + d_3.T @ a_2\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 ',delta2.shape)\n",
    "        \n",
    "        \n",
    "    delta1 /= lenth\n",
    "    delta2 /= lenth\n",
    "    \n",
    "    Deltas=np.hstack((delta1.ravel(order='F'), delta2.ravel(order='F')))\n",
    "   \n",
    "    return Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bckprop_wts = NN(ttl_weits, ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "#bckprop_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(wt1, wt2, X, y):\n",
    "    l = len(y)\n",
    "    ones = np.ones((l,1))\n",
    "    a_1 = np.hstack((ones, X))\n",
    "    a_2 = SIG(a_1 @ wt1.T)\n",
    "    a_2 = np.hstack((ones, a_2))\n",
    "    h = SIG(a_2 @ wt2.T)\n",
    "    return np.argmax(h, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def checkGradient(ttl_weits,bckprop_wts,iplyr, hdlyr, no_labls,Train_ip,Train_otpts):\n",
    "    eps = 0.22\n",
    "   \n",
    "    \n",
    "    for i in range(5):\n",
    "        iterattion = int(np.random.rand()*len(ttl_weits))\n",
    "        \n",
    "        adding_eps = np.zeros((len(ttl_weits),1))\n",
    "        \n",
    "        adding_eps[iterattion] = eps\n",
    "       \n",
    "\n",
    "        ThetaPlus = Feedfrwd(ttl_weits + adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ThetaMinus  = Feedfrwd(ttl_weits - adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts)\n",
    "        \n",
    "        \n",
    "        num_app = (ThetaPlus - ThetaMinus) / float(2*eps)\n",
    "        print('num_app',num_app)\n",
    "       \n",
    "        print('bckprop_wts[iterattion]',bckprop_wts[iterattion])\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_app -0.012884943617861501\n",
      "bckprop_wts[iterattion] -0.012885842830204258\n",
      "num_app -0.010816391146476175\n",
      "bckprop_wts[iterattion] -0.010826531600240177\n",
      "num_app 0.25373229674779246\n",
      "bckprop_wts[iterattion] 0.2538121914930991\n",
      "num_app 0.30795798493166765\n",
      "bckprop_wts[iterattion] 0.3080374231787549\n",
      "num_app 0.003043225082133283\n",
      "bckprop_wts[iterattion] 0.003043060435647263\n"
     ]
    }
   ],
   "source": [
    "result=checkGradient(ttl_weits,bckprop_wts,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "result# To check whether the numerical approximation and our back prop should be similar for atleast \n",
    "#first 3 digists such that our back propagation is appropriate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.993975\n",
      "         Iterations: 100\n",
      "         Function evaluations: 243\n",
      "         Gradient evaluations: 243\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "Final_wts = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts))\n",
    "\n",
    "\n",
    "Final_wts1,Final_wts2= Weights(Final_wts, ip_lyr, hd_lyr, no_labls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting y values for test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(Final_wts1, Final_wts2, XTest.iloc[:,:-1], yTest)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is :\n",
      "[[3 1 1 0]\n",
      " [3 8 0 0]\n",
      " [0 4 2 0]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_actual=XTest.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "print('The confusion matrix is :')\n",
    "print(  confusion_matrix(y_actual,pred))\n",
    "\n",
    "#print(accuracy_score(y_actual,pred))\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#accuracy_score(y_actual,pred)\n",
    "#print(type(y_test))\n",
    "\n",
    "#print(accuracy_score(y_actual,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.5406060606060606\n",
      "precision_score 0.5559006211180124\n",
      "recall_score 0.5652173913043478\n",
      "AUC score : 0.7549019607843137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred, average=\"weighted\"))  \n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_actual,pred, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr, tpr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
