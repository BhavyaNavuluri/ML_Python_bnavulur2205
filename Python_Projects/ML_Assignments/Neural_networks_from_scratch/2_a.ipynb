{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import scipy.optimize as opt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "CBSE_01             False\n",
       "CBSE_02             False\n",
       "LEVEL               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "\n",
    "\n",
    "# to check whether there are any empty values or not \n",
    "df=file[['all_mcqs_avg_n20', 'all_NBME_avg_n4', 'CBSE_01',  'CBSE_02', 'LEVEL']]\n",
    "\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "df[['CBSE_02']].fillna(method ='bfill')\n",
    "#.fillna(52, inplace=True)\n",
    "df.fillna(df['CBSE_02'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  CBSE_01  CBSE_02  LEVEL\n",
      "0               0.736           0.7700       42     68.0      1\n",
      "1               0.740           0.8000       44     67.0      2\n",
      "2               0.807           0.8125       41     78.0      0\n",
      "3               0.886           0.9250       68     91.0      0\n",
      "4               0.839           0.8550       57     74.0      1\n",
      "..                ...              ...      ...      ...    ...\n",
      "110             0.637           0.6825       45     52.0      2\n",
      "111             0.751           0.8150       53     60.0      2\n",
      "112             0.811           0.8325       50     77.0      1\n",
      "113             0.729           0.7275       43     68.0      2\n",
      "114             0.839           0.8625       54     73.0      1\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#onhtencder = OneHotEncoder(categorical_features = [0]) \n",
    "\n",
    "onhtencder= ColumnTransformer([(\"LEVEL\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "\n",
    "data = onhtencder.fit_transform(df[['LEVEL']]).toarray() \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df.iloc[:,:]\n",
    "\n",
    "X_norm = (X.iloc[:,:-1] - X.iloc[:,:-1].mean()) / (X.iloc[:,:-1].max() - X.iloc[:,:-1].min())\n",
    "\n",
    "\n",
    "\n",
    "X_modified = pd.concat([X_norm, X.iloc[:,-1]],axis=1)\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_modified, data, test_size=0.20,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train_ip=np.array(X_train.iloc[:,:-1])\n",
    "Train_otpts=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(ttl_weits,ip,hidn,otpt):\n",
    "    w1 = np.reshape(ttl_weits[:hidn*(ip+1)], (hidn, ip+1), 'F')\n",
    "    w2 = np.reshape(ttl_weits[hidn*(ip+1):], (otpt, hidn+1), 'F')\n",
    "    return w1,w2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIG(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def SIGGrad(z):\n",
    "    return np.multiply(SIG(z), 1-SIG(z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(h,y,wt1,wt2,l,lmbda):\n",
    "    cost = np.sum(np.multiply(y, np.log(h))+np.multiply(1-y, np.log(1-h)))\n",
    "    s_1 = np.sum(np.sum(np.power(wt1[:,1:],2), axis = 1))\n",
    "    \n",
    "    s_2 = np.sum(np.sum(np.power(wt2[:,1:],2), axis = 1))\n",
    "    \n",
    "    re= np.sum(cost / (-l)) + (s_1 + s_2) * lmbda / (2*l)    \n",
    "    \n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt1 [[0.51394334 0.77316505 0.87042769 0.00804695 0.30973593]]\n",
      "wt2 [[0.95760374 0.51311671]\n",
      " [0.31828442 0.53919994]\n",
      " [0.22125494 0.80648136]\n",
      " [0.34225463 0.53888885]]\n",
      "ttl_weits [0.51394334 0.77316505 0.87042769 0.00804695 0.30973593 0.95760374\n",
      " 0.31828442 0.22125494 0.34225463 0.51311671 0.53919994 0.80648136\n",
      " 0.53888885]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(14)\n",
    "\n",
    "wt1 = np.random.random((1,5))    \n",
    "wt2 = np.random.random((4,2))    \n",
    "ttl_weits = np.hstack((wt1.ravel(order='F'), wt2.ravel(order='F')))   \n",
    "\n",
    "# layers configuration \n",
    "\n",
    "ip_lyr = 4\n",
    "hd_lyr = 1\n",
    "no_labls = 4\n",
    "\n",
    "print('wt1',wt1)\n",
    "print('wt2',wt2)\n",
    "print('ttl_weits',ttl_weits)\n",
    "#print(ttl_weits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIG(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y, lmbda):\n",
    "    wt1,wt2= Weights(ttl_weits, ip_lyr, hd_lyr, no_labls)\n",
    "   \n",
    "    l = len(y)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    #print('ones',ones)\n",
    "    a1 = np.hstack((ones, X))\n",
    "    #print('a1',a1)\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    #print('a2',a2)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    #print('a2',a2)\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    #print('h',h)\n",
    "\n",
    "   \n",
    "    \n",
    "    c=Cost(h,Train_otpts,wt1,wt2,l,lmbda)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_er = Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip,Train_otpts,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y, lmbda):\n",
    "    \n",
    "    initt_wt1,initt_wt2= Weights(ttl_weits, ip_lyr, hd_lyr, no_labls)\n",
    "    \n",
    "  \n",
    "    lenth = len(y)\n",
    "\n",
    "    ones = np.ones((lenth,1))\n",
    "    \n",
    "    \n",
    "    a1 = np.hstack((ones, X))\n",
    "    #print('a1',a1)\n",
    "    #print('al shape',a1.shape)\n",
    "    z2 = a1 @ initt_wt1.T\n",
    "    #print('z2',z2)\n",
    "    #print('z2 sha',z2.shape)\n",
    "    a2 = np.hstack((ones, SIG(z2)))\n",
    "    #print('a2 ',a2)\n",
    "    #print('a2 ',a2.shape)\n",
    "    z3 = a2 @ initt_wt2.T\n",
    "    #print('z3',z3)\n",
    "    #print('z3 ',z3.shape)\n",
    "    a3 = SIG(z3)\n",
    "    #print('a3',a3)\n",
    "    #print('a3',a3.shape)\n",
    "    y1=pd.DataFrame(y)\n",
    "\n",
    "    d3 = a3 - y\n",
    "    #print('d3',d3)\n",
    "    #print('d3',d3.shape)\n",
    "    z2 = np.hstack((ones, z2))\n",
    "    #print('z2',z2)\n",
    "    #print('z2',z2.shape)\n",
    "    d2 = np.multiply(initt_wt2.T @ d3.T, SIGGrad(z2).T)\n",
    "    #print('d2',d2)\n",
    "    #print('d2',d2.shape)\n",
    "    delta1 = np.zeros(initt_wt1.shape)\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1 shape',delta1.shape)\n",
    "    delta2 = np.zeros(initt_wt2.shape)\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 shape',delta2.shape)\n",
    "    delta1 = delta1 + d2[1:,:] @ a1\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1',delta1.shape)\n",
    "    delta2 = delta2 + d3.T @ a2\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 ',delta2.shape)\n",
    "        \n",
    "        \n",
    "    delta1 /= lenth\n",
    "    delta2 /= lenth\n",
    "    #print(delta1.shape, delta2.shape)\n",
    "    delta1[:,1:] = delta1[:,1:] + initt_wt1[:,1:] * lmbda / lenth\n",
    "    delta2[:,1:] = delta2[:,1:] + initt_wt2[:,1:] * lmbda / lenth\n",
    "        \n",
    "    return np.hstack((delta1.ravel(order='F'), delta2.ravel(order='F')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bckprop_wts = NN(ttl_weits, ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(wt1, wt2, X, y):\n",
    "    l = len(y)\n",
    "    ones = np.ones((l,1))\n",
    "    a1 = np.hstack((ones, X))\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    return np.argmax(h, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def checkGradient(frwd_wts,bckprop_wts,iplyr, hdlyr, no_labls,Train_ip,Train_otpts,lmbda):\n",
    "    eps = 0.22\n",
    "   \n",
    "    \n",
    "    for i in range(5):\n",
    "        iterattion = int(np.random.rand()*len(frwd_wts))\n",
    "        #print('iterattion',iterattion)\n",
    "        adding_eps = np.zeros((len(frwd_wts),1))\n",
    "        #print('adding_eps',adding_eps)\n",
    "        adding_eps[iterattion] = eps\n",
    "        #print('adding_eps[iterattion]',adding_eps[iterattion])\n",
    "\n",
    "        ThetaPlus = Feedfrwd(frwd_wts + adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts,lmbda)\n",
    "        \n",
    "        #print('ThetaPlus',ThetaPlus)\n",
    "        \n",
    "        ThetaMinus  = Feedfrwd(frwd_wts - adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts,lmbda)\n",
    "        #print('ThetaMinus',ThetaMinus)\n",
    "        \n",
    "        num_app = (ThetaPlus - ThetaMinus) / float(2*eps)\n",
    "        print('num_app',num_app)\n",
    "       \n",
    "        print('bckprop_wts[iterattion]',bckprop_wts[iterattion])\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_app 0.23724924495991295\n",
      "bckprop_wts[iterattion] 0.2380399230891398\n",
      "num_app 0.618230677532917\n",
      "bckprop_wts[iterattion] 0.6188129273093341\n",
      "num_app 0.00784310494301519\n",
      "bckprop_wts[iterattion] 0.007837365514406388\n",
      "num_app 0.39201004235539316\n",
      "bckprop_wts[iterattion] 0.3921585715843909\n",
      "num_app 0.0017451302613203832\n",
      "bckprop_wts[iterattion] 0.0017433444037930138\n"
     ]
    }
   ],
   "source": [
    "grad_chk=checkGradient(ttl_weits,bckprop_wts,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 1)\n",
    "grad_chk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda =0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.404095\n",
      "         Iterations: 100\n",
      "         Function evaluations: 274\n",
      "         Gradient evaluations: 274\n",
      "[[4 0 1 0]\n",
      " [4 7 0 0]\n",
      " [0 4 2 0]\n",
      " [0 1 0 0]]\n",
      "f1_score 0.5408366051088168\n",
      "precision_score 0.5615942028985508\n",
      "recall_score 0.5652173913043478\n",
      "AUC score : 0.7941176470588236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "Final_wts_1 = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts,0.01))\n",
    "\n",
    "\n",
    "Final_wts1_1,Final_wts2_1= Weights(Final_wts_1, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "pred_1 = predict(Final_wts1_1, Final_wts2_1, X_test.iloc[:,:-1], y_test)\n",
    "\n",
    "\n",
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "print(confusion_matrix(y_actual,pred_1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred_1, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred_1, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred_1, average=\"weighted\"))  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpr_1, tpr_1, thresholds_1 = metrics.roc_curve(y_actual,pred_1, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr_1, tpr_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda =0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.760457\n",
      "         Iterations: 38\n",
      "         Function evaluations: 97\n",
      "         Gradient evaluations: 97\n",
      "[[4 0 1 0]\n",
      " [7 4 0 0]\n",
      " [0 5 1 0]\n",
      " [0 1 0 0]]\n",
      "f1_score 0.3561076604554866\n",
      "precision_score 0.4007905138339921\n",
      "recall_score 0.391304347826087\n",
      "AUC score : 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Final_wts_2 = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts,0.5))\n",
    "\n",
    "\n",
    "Final_wts1_2,Final_wts2_2= Weights(Final_wts_2, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "pred_2 = predict(Final_wts1_2, Final_wts2_2, X_test.iloc[:,:-1], y_test)\n",
    "\n",
    "\n",
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "print(confusion_matrix(y_actual,pred_2))\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred_2, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred_2, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred_2, average=\"weighted\"))  \n",
    "fpr_2, tpr_2, thresholds_2 = metrics.roc_curve(y_actual,pred_2, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr_2, tpr_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.890400\n",
      "         Iterations: 27\n",
      "         Function evaluations: 73\n",
      "         Gradient evaluations: 73\n",
      "[[4 0 1 0]\n",
      " [7 4 0 0]\n",
      " [0 5 1 0]\n",
      " [0 1 0 0]]\n",
      "f1_score 0.3561076604554866\n",
      "precision_score 0.4007905138339921\n",
      "recall_score 0.391304347826087\n",
      "AUC score : 0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "## Lambda =1\n",
    "\n",
    "\n",
    "\n",
    "Final_wts_3 = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts,1))\n",
    "\n",
    "\n",
    "Final_wts1_3,Final_wts2_3= Weights(Final_wts_3, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "pred_3 = predict(Final_wts1_3, Final_wts2_3, X_test.iloc[:,:-1], y_test)\n",
    "\n",
    "\n",
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "print(confusion_matrix(y_actual,pred_3))\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred_3, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred_3, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred_3, average=\"weighted\"))  \n",
    "\n",
    "\n",
    "fpr_3, tpr_3, thresholds_3 = metrics.roc_curve(y_actual,pred_3, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr_3, tpr_3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.040298\n",
      "         Iterations: 19\n",
      "         Function evaluations: 47\n",
      "         Gradient evaluations: 47\n",
      "[[ 0  5  0  0]\n",
      " [ 0 11  0  0]\n",
      " [ 0  6  0  0]\n",
      " [ 0  1  0  0]]\n",
      "f1_score 0.309462915601023\n",
      "precision_score 0.2287334593572779\n",
      "recall_score 0.4782608695652174\n",
      "AUC score : 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "Final_wts_4 = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts,5))\n",
    "\n",
    "\n",
    "Final_wts1_4,Final_wts2_4= Weights(Final_wts_4, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "pred_4 = predict(Final_wts1_4, Final_wts2_4, X_test.iloc[:,:-1], y_test)\n",
    "\n",
    "\n",
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "print(confusion_matrix(y_actual,pred_4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred_4, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred_4, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred_4, average=\"weighted\"))  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpr_4, tpr_4, thresholds_4 = metrics.roc_curve(y_actual,pred_4, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr_4, tpr_4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.040298\n",
      "         Iterations: 19\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "[[ 0  5  0  0]\n",
      " [ 0 11  0  0]\n",
      " [ 0  6  0  0]\n",
      " [ 0  1  0  0]]\n",
      "f1_score 0.309462915601023\n",
      "precision_score 0.2287334593572779\n",
      "recall_score 0.4782608695652174\n",
      "AUC score : 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "Final_wts_5 = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts,50))\n",
    "\n",
    "\n",
    "Final_wts1_5,Final_wts2_5= Weights(Final_wts_5, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "pred_5 = predict(Final_wts1_5, Final_wts2_5, X_test.iloc[:,:-1], y_test)\n",
    "\n",
    "\n",
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "print(confusion_matrix(y_actual,pred_5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred_5, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred_5, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred_5, average=\"weighted\"))  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpr_5, tpr_5, thresholds_5 = metrics.roc_curve(y_actual,pred_5, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr_5, tpr_5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
