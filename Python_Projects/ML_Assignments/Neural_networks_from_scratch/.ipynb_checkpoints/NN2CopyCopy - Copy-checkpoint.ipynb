{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "CBSE_01             False\n",
       "CBSE_02             False\n",
       "LEVEL               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "\n",
    "\n",
    "# to check whether there are any empty values or not \n",
    "df=file[['all_mcqs_avg_n20', 'all_NBME_avg_n4', 'CBSE_01',  'CBSE_02', 'LEVEL']]\n",
    "\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "df[['CBSE_02']].fillna(method ='bfill')\n",
    "#.fillna(52, inplace=True)\n",
    "df.fillna(df['CBSE_02'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  CBSE_01  CBSE_02  LEVEL\n",
      "0               0.736           0.7700       42     68.0      1\n",
      "1               0.740           0.8000       44     67.0      2\n",
      "2               0.807           0.8125       41     78.0      0\n",
      "3               0.886           0.9250       68     91.0      0\n",
      "4               0.839           0.8550       57     74.0      1\n",
      "..                ...              ...      ...      ...    ...\n",
      "110             0.637           0.6825       45     52.0      2\n",
      "111             0.751           0.8150       53     60.0      2\n",
      "112             0.811           0.8325       50     77.0      1\n",
      "113             0.729           0.7275       43     68.0      2\n",
      "114             0.839           0.8625       54     73.0      1\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onhtencder = OneHotEncoder(categorical_features = [0]) \n",
    "data = onhtencder.fit_transform(df[['LEVEL']]).toarray() \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 5)\n",
      "(23, 5)\n",
      "(92, 4)\n",
      "(23, 4)\n"
     ]
    }
   ],
   "source": [
    "X= df.iloc[:,:]\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,data, test_size=0.20,random_state=8)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SIG function to normalize inputs\n",
    "def SIG(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# SIG derivatives to adjust synaptic weights\n",
    "def SIG_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# input dataset\n",
    "\n",
    "Train_ip=np.array(X_train.iloc[:,:-1])\n",
    "Train_otpts=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt1 [[-0.03646108  0.50251222 -0.56224632 -0.33844343 -0.36419397]\n",
      " [ 0.26577659 -0.96772307  0.99525651  0.10160335 -0.65546691]\n",
      " [-0.66978705 -0.54295816 -0.68700835  0.7501182   0.03675303]\n",
      " [-0.35528535 -0.50414364  0.04211714  0.30637627  0.782585  ]\n",
      " [ 0.53550941 -0.26214469 -0.2999868  -0.14494235 -0.96740647]]\n",
      "wt2 [[-0.55836274  0.02292443  0.57662062 -0.629954    0.09165626  0.59639009]\n",
      " [-0.34779812 -0.64666293  0.08791179  0.43510036 -0.49570395  0.41077613]\n",
      " [-0.40952549 -0.37652616  0.30032554 -0.16986881  0.64712294 -0.32062312]\n",
      " [-0.94932257  0.16280969  0.32110455  0.28290954 -0.99072528  0.19801552]]\n",
      "ttl_weits [-0.03646108  0.26577659 -0.66978705 -0.35528535  0.53550941  0.50251222\n",
      " -0.96772307 -0.54295816 -0.50414364 -0.26214469 -0.56224632  0.99525651\n",
      " -0.68700835  0.04211714 -0.2999868  -0.33844343  0.10160335  0.7501182\n",
      "  0.30637627 -0.14494235 -0.36419397 -0.65546691  0.03675303  0.782585\n",
      " -0.96740647 -0.55836274 -0.34779812 -0.40952549 -0.94932257  0.02292443\n",
      " -0.64666293 -0.37652616  0.16280969  0.57662062  0.08791179  0.30032554\n",
      "  0.32110455 -0.629954    0.43510036 -0.16986881  0.28290954  0.09165626\n",
      " -0.49570395  0.64712294 -0.99072528  0.59639009  0.41077613 -0.32062312\n",
      "  0.19801552]\n",
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.io import loadmat\n",
    "#weights = to_matrix('Train_ip')\n",
    "wt1 = 2 * np.random.random((5,5))- 1    \n",
    "wt2 = 2 * np.random.random((4,6))- 1    \n",
    "ttl_weits = np.hstack((wt1.ravel(order='F'), wt2.ravel(order='F')))    #unrolling the  params\n",
    "\n",
    "# layers configuration \n",
    "\n",
    "ip_lyr = 4\n",
    "hd_lyr = 5\n",
    "no_labls = 4\n",
    "#lmbda = 1\n",
    "print('wt1',wt1)\n",
    "print('wt2',wt2)\n",
    "print('ttl_weits',ttl_weits)\n",
    "print(ttl_weits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttl_weits [-0.03646108  0.26577659 -0.66978705 -0.35528535  0.53550941  0.50251222\n",
      " -0.96772307 -0.54295816 -0.50414364 -0.26214469 -0.56224632  0.99525651\n",
      " -0.68700835  0.04211714 -0.2999868  -0.33844343  0.10160335  0.7501182\n",
      "  0.30637627 -0.14494235 -0.36419397 -0.65546691  0.03675303  0.782585\n",
      " -0.96740647 -0.55836274 -0.34779812 -0.40952549 -0.94932257  0.02292443\n",
      " -0.64666293 -0.37652616  0.16280969  0.57662062  0.08791179  0.30032554\n",
      "  0.32110455 -0.629954    0.43510036 -0.16986881  0.28290954  0.09165626\n",
      " -0.49570395  0.64712294 -0.99072528  0.59639009  0.41077613 -0.32062312\n",
      "  0.19801552]\n"
     ]
    }
   ],
   "source": [
    "print('ttl_weits',ttl_weits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIG(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y, lmbda):\n",
    "    wt1 = np.reshape(ttl_weits[:hd_lyr*(ip_lyr+1)], (hd_lyr, ip_lyr+1), 'F')\n",
    "    wt2 = np.reshape(ttl_weits[hd_lyr*(ip_lyr+1):], (no_labls, hd_lyr+1), 'F')\n",
    "\n",
    "   \n",
    "    l = len(y)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    #print('ones',ones)\n",
    "    a1 = np.hstack((ones, X))\n",
    "    #print('a1',a1)\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    #print('a2',a2)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    #print('a2',a2)\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    #print('h',h)\n",
    "\n",
    "   \n",
    "    \n",
    "    cost = np.sum(np.multiply(y, np.log(h))+np.multiply(1-y, np.log(1-h)))\n",
    "    #print('cost',cost)\n",
    "    \n",
    "\n",
    "    sum1 = np.sum(np.sum(np.power(wt1[:,1:],2), axis = 1))\n",
    "    #print('sum1',sum1)\n",
    "    sum2 = np.sum(np.sum(np.power(wt2[:,1:],2), axis = 1))\n",
    "    #print('sum2',sum2)\n",
    "    return np.sum(cost / (-l)) + (sum1 + sum2) * lmbda / (2*l)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_er = Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip,Train_otpts, lmbda)\n",
    "cf_er.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIGGrad(z):\n",
    "    return np.multiply(SIG(z), 1-SIG(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(h, y_train):\n",
    "    loss=np.sum((cf_er-y_train)**2)/2.0\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def randInitializeWeights(L_in, L_out):\n",
    "    epsilon = 0.12\n",
    "    return np.random.rand(L_out, L_in+1) * 2 * epsilon - epsilon\n",
    "\n",
    "initial_wt1 = randInitializeWeights(ip_lyr, hd_lyr)\n",
    "initial_wt2 = randInitializeWeights(hd_lyr, no_labls)\n",
    "\n",
    "# unrolling parameters into a single column vector\n",
    "nn_initial_params = np.hstack((initial_wt1.ravel(order='F'), initial_wt2.ravel(order='F')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnGrad(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y, lmbda):\n",
    "    \n",
    "    init_wt1 = np.reshape(ttl_weits[:hd_lyr*(ip_lyr+1)], (hd_lyr, ip_lyr+1), 'F')\n",
    "    initial_wt2 = np.reshape(ttl_weits[hd_lyr*(ip_lyr+1):], (no_labls, hd_lyr+1), 'F')\n",
    "    \n",
    "    delta1 = np.zeros(initial_wt1.shape)\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1 shape',delta1.shape)\n",
    "    delta2 = np.zeros(initial_wt2.shape)\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 shape',delta2.shape)\n",
    "    lenth = len(y)\n",
    "\n",
    "    ones = np.ones((lenth,1))\n",
    "    \n",
    "    \n",
    "    a1 = np.hstack((ones, X))\n",
    "    #print('a1',a1)\n",
    "    #print('al shape',a1.shape)\n",
    "    z2 = a1 @ initial_wt1.T\n",
    "    #print('z2',z2)\n",
    "    #print('z2 sha',z2.shape)\n",
    "    a2 = np.hstack((ones, SIG(z2)))\n",
    "    #print('a2 ',a2)\n",
    "    #print('a2 ',a2.shape)\n",
    "    z3 = a2 @ initial_wt2.T\n",
    "    #print('z3',z3)\n",
    "    #print('z3 ',z3.shape)\n",
    "    a3 = SIG(z3)\n",
    "    #print('a3',a3)\n",
    "    #print('a3',a3.shape)\n",
    "    y1=pd.DataFrame(y)\n",
    "\n",
    "    d3 = a3 - y\n",
    "    #print('d3',d3)\n",
    "    #print('d3',d3.shape)\n",
    "    z2 = np.hstack((ones, z2))\n",
    "    #print('z2',z2)\n",
    "    #print('z2',z2.shape)\n",
    "    d2 = np.multiply(initial_wt2.T @ d3.T, SIGGrad(z2).T)\n",
    "    #print('d2',d2)\n",
    "    #print('d2',d2.shape)\n",
    "    delta1 = delta1 + d2[1:,:] @ a1\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1',delta1.shape)\n",
    "    delta2 = delta2 + d3.T @ a2\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 ',delta2.shape)\n",
    "        \n",
    "        \n",
    "    delta1 /= lenth\n",
    "    delta2 /= lenth\n",
    "    #print(delta1.shape, delta2.shape)\n",
    "    delta1[:,1:] = delta1[:,1:] + initial_wt1[:,1:] * lmbda / lenth\n",
    "    delta2[:,1:] = delta2[:,1:] + initial_wt2[:,1:] * lmbda / lenth\n",
    "        \n",
    "    return np.hstack((delta1.ravel(order='F'), delta2.ravel(order='F')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.04544852e-03,  6.55848320e-06, -1.24209949e-04, -5.66811230e-06,\n",
       "        5.81185349e-04, -1.34362829e-04,  8.54255968e-04, -9.89704301e-04,\n",
       "       -8.81262091e-04,  1.64218518e-03,  1.60567261e-03,  1.03850532e-03,\n",
       "       -1.10106710e-03,  8.85760996e-04, -4.48559939e-04,  6.15322057e-02,\n",
       "        6.51311055e-04, -5.55164429e-03,  1.29526966e-04,  2.48751354e-02,\n",
       "        1.06265749e-01,  1.53233227e-03, -6.04569991e-03,  5.67237821e-04,\n",
       "        3.99321165e-02,  1.82280342e-01,  1.03882146e-01,  2.54489598e-01,\n",
       "        4.64715040e-01,  2.40478605e-02,  8.64775550e-03,  1.98176126e-02,\n",
       "        4.45035045e-02,  1.82005377e-01,  1.04310870e-01,  2.54709218e-01,\n",
       "        4.65588913e-01,  1.78358861e-01,  1.02179169e-01,  2.52654954e-01,\n",
       "        4.61815698e-01,  1.82894676e-01,  1.03633700e-01,  2.54694786e-01,\n",
       "        4.63505309e-01,  2.46506469e-03,  1.48912134e-03,  1.98155009e-03,\n",
       "        5.70889198e-03])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_backprop_Params = nnGrad(nn_initial_params, ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, lmbda)\n",
    "\n",
    "nn_backprop_Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def checkGradient(nn_initial_params,nn_backprop_Params,ip_lyr, hd_lyr, no_labls,myX,myy,mylambda):\n",
    "    myeps = 0.0001\n",
    "    flattened = nn_initial_params\n",
    "    #print('flattened',flattened)\n",
    "    flattenedDs = nn_backprop_Params\n",
    "    #print('flattenedDs',flattenedDs)\n",
    "    n_elems = len(flattened) \n",
    "    \n",
    "    for i in range(10):\n",
    "        x = int(np.random.rand()*n_elems)\n",
    "        #print('x',x)\n",
    "        epsvec = np.zeros((n_elems,1))\n",
    "        #print('epsvec',epsvec)\n",
    "        epsvec[x] = myeps\n",
    "        #print('epsvec[x]',epsvec[x])\n",
    "\n",
    "        cost_high = Feedfrwd(flattened + epsvec.flatten(),ip_lyr, hd_lyr, no_labls,myX,myy,mylambda)\n",
    "        #print('cost_high',cost_high)\n",
    "        cost_low  = Feedfrwd(flattened - epsvec.flatten(),ip_lyr, hd_lyr, no_labls,myX,myy,mylambda)\n",
    "        #print('cost_low',cost_low)\n",
    "        mygrad = (cost_high - cost_low) / float(2*myeps)\n",
    "        print('mygrad',mygrad)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('flattenedDs[x]',flattenedDs[x])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mygrad 0.10431087026807617\n",
      "flattenedDs[x] 0.10431087028351728\n",
      "mygrad 0.25448959847240715\n",
      "flattenedDs[x] 0.2544895984673991\n",
      "mygrad -0.0008812620921894165\n",
      "flattenedDs[x] -0.0008812620906276518\n",
      "mygrad 0.002465064690149177\n",
      "flattenedDs[x] 0.0024650646910506805\n",
      "mygrad 0.2547092183124988\n",
      "flattenedDs[x] 0.2547092183049459\n",
      "mygrad 0.0016056726104274333\n",
      "flattenedDs[x] 0.0016056726123598133\n",
      "mygrad -0.00013436282531031907\n",
      "flattenedDs[x] -0.0001343628290450896\n",
      "mygrad -0.005551660886560228\n",
      "flattenedDs[x] -0.005551644285699108\n",
      "mygrad 0.0008857609956613999\n",
      "flattenedDs[x] 0.0008857609963744992\n",
      "mygrad 0.46350530948924273\n",
      "flattenedDs[x] 0.4635053094852041\n"
     ]
    }
   ],
   "source": [
    "grad=checkGradient(nn_initial_params,nn_backprop_Params,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, lmbda)\n",
    "#grad_2=checkGradient(nn_initial_params,nn_backprop_Params,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 0.01)\n",
    "#grad_3=checkGradient(nn_initial_params,nn_backprop_Params,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 0.001)\n",
    "#grad_4=checkGradient(nn_initial_params,nn_backprop_Params,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 5)\n",
    "#grad_5=checkGradient(nn_initial_params,nn_backprop_Params,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 20)\n",
    "\n",
    "\n",
    "#grad_1,grad_2,grad_3,grad_4,grad_5\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 1.995477\n",
      "         Iterations: 3\n",
      "         Function evaluations: 37\n",
      "         Gradient evaluations: 27\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "theta_opt = opt.fmin_cg(maxiter = 50, f = Feedfrwd, x0 = nn_initial_params, fprime = nnGrad, \\\n",
    "                        args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts, 0.001))\n",
    "\n",
    "wt1_opt = np.reshape(theta_opt[:hd_lyr*(ip_lyr+1)], (hd_lyr, ip_lyr+1), 'F')\n",
    "wt2_opt = np.reshape(theta_opt[hd_lyr*(ip_lyr+1):], (no_labls, hd_lyr+1), 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01396306, -0.10919979,  0.04701509,  0.03308034, -0.09633308],\n",
       "        [ 0.03321912,  0.07815914,  0.09509838,  0.03451378,  0.10508354],\n",
       "        [ 0.07811538, -0.0822068 , -0.09227023,  0.0547973 ,  0.13810172],\n",
       "        [ 0.0648952 , -0.08071738,  0.08185537,  0.03073946,  0.08668389],\n",
       "        [ 0.08435484,  0.11003833, -0.08368444, -0.14904924, -0.05770846]]),\n",
       " array([[-1.37123566e-01, -1.73218996e-01, -2.04378384e-01,\n",
       "         -2.80408479e-01, -1.04365772e-01, -4.61537739e-04],\n",
       "        [ 7.98742697e-03, -9.70709269e-02, -5.37205511e-02,\n",
       "         -1.54115720e-01, -1.07682061e-01,  5.76012295e-02],\n",
       "        [-3.16088281e-01,  4.00962388e-02, -2.65399499e-01,\n",
       "         -3.40476333e-01, -2.60208972e-01,  5.97792000e-03],\n",
       "        [-9.12292520e-01,  2.34915857e-02, -7.23200242e-01,\n",
       "         -7.26581478e-01, -8.91819555e-01,  1.08478305e-01]]))"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt1_opt,wt2_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(wt1, wt2, X, y):\n",
    "    l = len(y)\n",
    "    ones = np.ones((l,1))\n",
    "    a1 = np.hstack((ones, X))\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    return np.argmax(h, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(wt1_opt, wt2_opt, X_test.iloc[:,:-1], y_test)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 5 0 0]\n",
      " [0 8 0 0]\n",
      " [0 8 0 0]\n",
      " [0 2 0 0]]\n",
      "0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_actual,pred))\n",
    "\n",
    "#print(accuracy_score(y_actual,pred))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_actual,pred)\n",
    "#print(type(y_test))\n",
    "\n",
    "print(accuracy_score(y_actual,pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555330859059091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual=X_test.iloc[:,-1]\n",
    "\n",
    "rmse=np.sqrt( np.sum((pred-y_actual)**2) /len(y_actual))\n",
    "print(rmse)\n",
    "mse=np.sum((pred-y_actual)**2) /len(y_actual)\n",
    "mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
