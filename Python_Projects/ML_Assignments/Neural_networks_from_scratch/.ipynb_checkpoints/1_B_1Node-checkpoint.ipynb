{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "CBSE_01             False\n",
       "CBSE_02             False\n",
       "LEVEL               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "\n",
    "\n",
    "# to check whether there are any empty values or not \n",
    "df=file[['all_mcqs_avg_n20', 'all_NBME_avg_n4', 'CBSE_01',  'CBSE_02', 'LEVEL']]\n",
    "\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "df[['CBSE_02']].fillna(method ='bfill')\n",
    "#.fillna(52, inplace=True)\n",
    "df.fillna(df['CBSE_02'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  CBSE_01  CBSE_02  LEVEL\n",
      "0               0.736           0.7700       42     68.0      1\n",
      "1               0.740           0.8000       44     67.0      2\n",
      "2               0.807           0.8125       41     78.0      0\n",
      "3               0.886           0.9250       68     91.0      0\n",
      "4               0.839           0.8550       57     74.0      1\n",
      "..                ...              ...      ...      ...    ...\n",
      "110             0.637           0.6825       45     52.0      2\n",
      "111             0.751           0.8150       53     60.0      2\n",
      "112             0.811           0.8325       50     77.0      1\n",
      "113             0.729           0.7275       43     68.0      2\n",
      "114             0.839           0.8625       54     73.0      1\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#onhtencder = OneHotEncoder(categorical_features = [0]) \n",
    "\n",
    "onhtencder= ColumnTransformer([(\"LEVEL\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "\n",
    "data = onhtencder.fit_transform(df[['LEVEL']]).toarray() \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df.iloc[:,:]\n",
    "\n",
    "X_norm = (X.iloc[:,:-1] - X.iloc[:,:-1].mean()) / (X.iloc[:,:-1].max() - X.iloc[:,:-1].min())\n",
    "\n",
    "\n",
    "\n",
    "X_modified = pd.concat([X_norm, X.iloc[:,-1]],axis=1)\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_modified, data, test_size=0.20,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(ttl_weits,ip,hidn,otpt):\n",
    "    w1 = np.reshape(ttl_weits[:hidn*(ip+1)], (hidn, ip+1), 'F')\n",
    "    w2 = np.reshape(ttl_weits[hidn*(ip+1):], (otpt, hidn+1), 'F')\n",
    "    return w1,w2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SIG function to normalize inputs\n",
    "def SIG(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# SIG derivatives to adjust synaptic weights\n",
    "def SIGGrad(z):\n",
    "    return np.multiply(SIG(z), 1-SIG(z))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(h,y):\n",
    "    cost = np.sum(np.multiply(y, np.log(h))+np.multiply(1-y, np.log(1-h)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ip=np.array(X_train.iloc[:,:-1])\n",
    "Train_otpts=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt1 [[0.20846054 0.48168106 0.42053804 0.859182   0.17116155]]\n",
      "wt2 [[0.33886396 0.27053283]\n",
      " [0.69104135 0.22040452]\n",
      " [0.81195092 0.01052687]\n",
      " [0.5612037  0.81372619]]\n",
      "ttl_weits [0.20846054 0.48168106 0.42053804 0.859182   0.17116155 0.33886396\n",
      " 0.69104135 0.81195092 0.5612037  0.27053283 0.22040452 0.01052687\n",
      " 0.81372619]\n",
      "(13,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(22)\n",
    "\n",
    "wt1 =  np.random.random((1,5))#- 1    \n",
    "wt2 =  np.random.random((4,2))    \n",
    "ttl_weits = np.hstack((wt1.ravel(order='F'), wt2.ravel(order='F')))    \n",
    "\n",
    "# layers configuration \n",
    "\n",
    "ip_lyr = 4\n",
    "hd_lyr = 1\n",
    "no_labls = 4\n",
    "\n",
    "print('wt1',wt1)\n",
    "print('wt2',wt2)\n",
    "print('ttl_weits',ttl_weits)\n",
    "print(ttl_weits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y):\n",
    "    wt1 ,wt2= Weights(ttl_weits,ip_lyr,hd_lyr,no_labls)\n",
    "\n",
    "    \n",
    "    l = len(y)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    #print('ones',ones)\n",
    "    a1 = np.hstack((ones, X))\n",
    "    #print('a1',a1)\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    #print('a2',a2)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    #print('a2',a2)\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    #print('h',h)\n",
    "\n",
    "   \n",
    "    \n",
    "    c=Cost(h,Train_otpts)\n",
    "    \n",
    "    return c / (-l)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_er = Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip,Train_otpts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y):\n",
    "    \n",
    "    initt_wt1,initt_wt2 = Weights(ttl_weits,ip_lyr,hd_lyr,no_labls)\n",
    "    delta1 = np.zeros(initt_wt1.shape)\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1 shape',delta1.shape)\n",
    "    delta2 = np.zeros(initt_wt2.shape)\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 shape',delta2.shape)\n",
    "    lenth = len(y)\n",
    "\n",
    "    ones = np.ones((lenth,1))\n",
    "    \n",
    "    \n",
    "    a1 = np.hstack((ones, X))\n",
    "    #print('a1',a1)\n",
    "    #print('al shape',a1.shape)\n",
    "    z2 = a1 @ initt_wt1.T\n",
    "    #print('z2',z2)\n",
    "    #print('z2 sha',z2.shape)\n",
    "    a2 = np.hstack((ones, SIG(z2)))\n",
    "    #print('a2 ',a2)\n",
    "    #print('a2 ',a2.shape)\n",
    "    z3 = a2 @ initt_wt2.T\n",
    "    #print('z3',z3)\n",
    "    #print('z3 ',z3.shape)\n",
    "    a3 = SIG(z3)\n",
    "    #print('a3',a3)\n",
    "    #print('a3',a3.shape)\n",
    "    y1=pd.DataFrame(y)\n",
    "\n",
    "    d3 = a3 - y\n",
    "    #print('d3',d3)\n",
    "    #print('d3',d3.shape)\n",
    "    z2 = np.hstack((ones, z2))\n",
    "    #print('z2',z2)\n",
    "    #print('z2',z2.shape)\n",
    "    d2 = np.multiply(initt_wt2.T @ d3.T, SIGGrad(z2).T)\n",
    "    #print('d2',d2)\n",
    "    #print('d2',d2.shape)\n",
    "    delta1 = delta1 + d2[1:,:] @ a1\n",
    "    #print('delta1',delta1)\n",
    "    #print('delta1',delta1.shape)\n",
    "    delta2 = delta2 + d3.T @ a2\n",
    "    #print('delta2',delta2)\n",
    "    #print('delta2 ',delta2.shape)\n",
    "        \n",
    "        \n",
    "    delta1 /= lenth\n",
    "    delta2 /= lenth\n",
    "   \n",
    "    return np.hstack((delta1.ravel(order='F'), delta2.ravel(order='F')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bckprop_wts = NN(ttl_weits, ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "#bckprop_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(wt1, wt2, X, y):\n",
    "    l = len(y)\n",
    "    ones = np.ones((l,1))\n",
    "    a1 = np.hstack((ones, X))\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    return np.argmax(h, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def checkGradient(ttl_weits,bckprop_wts,iplyr, hdlyr, no_labls,Train_ip,Train_otpts):\n",
    "    eps = 0.22\n",
    "   \n",
    "    \n",
    "    for i in range(5):\n",
    "        iterattion = int(np.random.rand()*len(ttl_weits))\n",
    "        #print('iterattion',iterattion)\n",
    "        adding_eps = np.zeros((len(ttl_weits),1))\n",
    "        #print('adding_eps',adding_eps)\n",
    "        adding_eps[iterattion] = eps\n",
    "        #print('adding_eps[iterattion]',adding_eps[iterattion])\n",
    "\n",
    "        ThetaPlus = Feedfrwd(ttl_weits + adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts)\n",
    "        \n",
    "        #print('ThetaPlus',ThetaPlus)\n",
    "        \n",
    "        ThetaMinus  = Feedfrwd(ttl_weits - adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts)\n",
    "        #print('ThetaMinus',ThetaMinus)\n",
    "        \n",
    "        num_app = (ThetaPlus - ThetaMinus) / float(2*eps)\n",
    "        print('num_app',num_app)\n",
    "       \n",
    "        print('bckprop_wts[iterattion]',bckprop_wts[iterattion])\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_app 0.14451221291702812\n",
      "bckprop_wts[iterattion] 0.1445916205321833\n",
      "num_app -0.0033283890953048826\n",
      "bckprop_wts[iterattion] -0.0033315205008140917\n",
      "num_app 0.1725310969982559\n",
      "bckprop_wts[iterattion] 0.17318609441646016\n",
      "num_app 0.17229684529790548\n",
      "bckprop_wts[iterattion] 0.17241141769797821\n",
      "num_app 0.3789769973031507\n",
      "bckprop_wts[iterattion] 0.37910457943231274\n"
     ]
    }
   ],
   "source": [
    "grad_chk=checkGradient(ttl_weits,bckprop_wts,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "grad_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.349173\n",
      "         Iterations: 100\n",
      "         Function evaluations: 287\n",
      "         Gradient evaluations: 287\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "Final_wts = opt.fmin_cg(maxiter = 100, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts))\n",
    "\n",
    "\n",
    "Final_wts1,Final_wts2= Weights(Final_wts, ip_lyr, hd_lyr, no_labls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.63666748e+00,  3.04452619e+00,  4.97599262e+00, -2.75562449e+00,\n",
       "        9.27669942e+00, -3.27582789e+00,  1.58165312e-02,  3.88281267e-01,\n",
       "       -2.28514774e+00,  9.74023178e+00, -2.54296509e+00, -3.13574078e+01,\n",
       "       -1.48847583e+01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting y values for test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(Final_wts1,Final_wts2, X_test.iloc[:,:-1], y_test)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 1 0]\n",
      " [4 7 0 0]\n",
      " [0 4 2 0]\n",
      " [0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_actual,pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.5408366051088168\n",
      "precision_score 0.5615942028985508\n",
      "recall_score 0.5652173913043478\n",
      "AUC score : 0.7941176470588236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred, average=\"weighted\"))  \n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_actual,pred, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
