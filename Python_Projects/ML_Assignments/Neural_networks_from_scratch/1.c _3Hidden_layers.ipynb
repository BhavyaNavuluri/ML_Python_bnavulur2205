{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "CBSE_01             False\n",
       "CBSE_02             False\n",
       "LEVEL               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "\n",
    "\n",
    "# to check whether there are any empty values or not \n",
    "df=file[['all_mcqs_avg_n20', 'all_NBME_avg_n4', 'CBSE_01',  'CBSE_02', 'LEVEL']]\n",
    "\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "df[['CBSE_02']].fillna(method ='bfill')\n",
    "#.fillna(52, inplace=True)\n",
    "df.fillna(df['CBSE_02'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  CBSE_01  CBSE_02  LEVEL\n",
      "0               0.736           0.7700       42     68.0      1\n",
      "1               0.740           0.8000       44     67.0      2\n",
      "2               0.807           0.8125       41     78.0      0\n",
      "3               0.886           0.9250       68     91.0      0\n",
      "4               0.839           0.8550       57     74.0      1\n",
      "..                ...              ...      ...      ...    ...\n",
      "110             0.637           0.6825       45     52.0      2\n",
      "111             0.751           0.8150       53     60.0      2\n",
      "112             0.811           0.8325       50     77.0      1\n",
      "113             0.729           0.7275       43     68.0      2\n",
      "114             0.839           0.8625       54     73.0      1\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming y to binary number using one-hot- encoding\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#onhtencder = OneHotEncoder(categorical_features = [0]) \n",
    "\n",
    "onhtencder= ColumnTransformer([(\"LEVEL\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "\n",
    "data = onhtencder.fit_transform(df[['LEVEL']]).toarray() \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df.iloc[:,:]\n",
    "\n",
    "X_norm = (X.iloc[:,:-1] - X.iloc[:,:-1].mean()) / (X.iloc[:,:-1].max() - X.iloc[:,:-1].min())\n",
    "\n",
    "\n",
    "\n",
    "X_modified = pd.concat([X_norm, X.iloc[:,-1]],axis=1)\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_modified, data, test_size=0.20,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train_ip=np.array(X_train.iloc[:,:-1])\n",
    "Train_otpts=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt1 [[-0.55601366  0.74146461 -0.58656169  0.83722182 -0.02317762]]\n",
      "wt2 [[ 0.22348773  0.53181571]\n",
      " [ 0.03683598 -0.406399  ]]\n",
      "wt3 [[-0.62455754 -0.83851746  0.47688059]\n",
      " [-0.11738155 -0.68338026  0.75987406]]\n",
      "wt4 [[-0.45182708 -0.17152996 -0.40784013]\n",
      " [ 0.25757582  0.15967562  0.19985839]\n",
      " [-0.46836176 -0.43062824 -0.49282359]\n",
      " [-0.3448721  -0.7116714  -0.66877428]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing weights randomly\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "wt1 = 2 * np.random.random((1,5))- 1  \n",
    "\n",
    "\n",
    "wt2 = 2 * np.random.random((2,2))- 1   \n",
    "\n",
    "wt3 = 2 * np.random.random((2,3))- 1  \n",
    "\n",
    "wt4 = 2 * np.random.random((4,3))- 1   \n",
    "\n",
    "\n",
    "ttl_weits = np.hstack((wt1.ravel(order='F'), wt2.ravel(order='F'),wt3.ravel(order='F'),wt4.ravel(order='F')))    \n",
    "\n",
    "# layers configuration \n",
    "\n",
    "ip_lyr = 4\n",
    "hd_lyr1 = 1\n",
    "hd_lyr2 = 2\n",
    "hd_lyr3 = 2\n",
    "no_labls = 4\n",
    "\n",
    "print('wt1',wt1)\n",
    "print('wt2',wt2)\n",
    "print('wt3',wt3)\n",
    "print('wt4',wt4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls):\n",
    "\n",
    "    \n",
    "    w1 = np.reshape(ttl_weits[:hd_lyr1*(ip_lyr+1)], (hd_lyr1, ip_lyr+1), 'F')\n",
    "    w2 = np.reshape(ttl_weits[(ip_lyr+1):((ip_lyr+1)+hd_lyr2*(hd_lyr1+1))], (hd_lyr2, hd_lyr1+1), 'F')\n",
    "    w3 = np.reshape(ttl_weits[((ip_lyr+1)+hd_lyr2*(hd_lyr1+1)):(((ip_lyr+1)+hd_lyr2*(hd_lyr1+1))+hd_lyr3*(hd_lyr2+1))], (hd_lyr3, hd_lyr2+1), 'F')\n",
    "    w4 = np.reshape(ttl_weits[(((ip_lyr+1)+hd_lyr2*(hd_lyr1+1))+hd_lyr3*(hd_lyr2+1)):], (no_labls, hd_lyr3+1), 'F')\n",
    "\n",
    "   \n",
    "    return w1,w2,w3,w4\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sigmoid  function \n",
    "def SIG(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "def SIGGrad(z):\n",
    "    return np.multiply(SIG(z), 1-SIG(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(h,y):\n",
    "    cost = np.sum(np.multiply(y, np.log(h))+np.multiply(1-y, np.log(1-h)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feedfrwd(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls, Train_ip, Train_otpts):\n",
    "    \n",
    "    wt1,wt2,wt3,wt4 = Weights(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls)\n",
    "    \n",
    " \n",
    "    l = len(Train_ip)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    \n",
    "    a1 = np.hstack((ones, Train_ip))\n",
    "    \n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    \n",
    "    a2 = np.hstack((ones, a2))\n",
    "    \n",
    "    a3 = SIG(a2 @ wt2.T)\n",
    "    \n",
    "    a3 = np.hstack((ones, a3))\n",
    "    \n",
    "    a4 = SIG(a3 @ wt3.T)\n",
    "    \n",
    "    a4 = np.hstack((ones, a4))\n",
    "    \n",
    "    h = SIG(a4 @ wt4.T)\n",
    "    \n",
    "    c=Cost(h,Train_otpts)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return c / (-l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3188907772655325"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_er = Feedfrwd(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls, Train_ip,Train_otpts)\n",
    "cf_er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls,Train_ip,Train_otpts):\n",
    "    \n",
    "    \n",
    "    initt_wt1,initt_wt2,initt_wt3,initt_wt4 = Weights(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    l = len(Train_otpts)\n",
    "\n",
    "    ones = np.ones((l,1))\n",
    "    a1 = np.hstack((ones, Train_ip))\n",
    "    #print('a1',a1)\n",
    "    #print('a1',a1.shape)\n",
    "    z2 = a1 @ initt_wt1.T\n",
    "    #print('z2',z2)\n",
    "    #print('z2',z2.shape)\n",
    "    a2 = np.hstack((ones, SIG(z2)))\n",
    "    #print('a2',a2)\n",
    "    #print('a2',a2.shape)\n",
    "    z3 = a2 @ initt_wt2.T\n",
    "    #print('z3',z3)\n",
    "    #print('z3',z3.shape)\n",
    "    a3 = np.hstack((ones, SIG(z3)))\n",
    "    #print('a3',a3)\n",
    "    #print('a3',a3.shape)\n",
    "    #print('',.shape)print('',)\n",
    "    z4 = a3 @ initt_wt3.T\n",
    "    \n",
    "    a4 = np.hstack((ones, SIG(z4)))\n",
    "    \n",
    "    z5 = a4 @ initt_wt4.T\n",
    "    \n",
    "    a5 = SIG(z5)\n",
    "    #print(a5.shape)\n",
    "    \n",
    "    d5 = a5-Train_otpts\n",
    "    l = len(Train_otpts)\n",
    "\n",
    "    ones = np.ones((l,1))\n",
    "    z4 = np.hstack((ones, z4))\n",
    "    d4 = np.multiply(initt_wt4.T @ d5.T, SIGGrad(z4).T)\n",
    "    \n",
    "    z3 = np.hstack((ones, z3))\n",
    "    d3 = np.multiply(initt_wt3.T @ d4[1:], SIGGrad(z3).T)\n",
    "    z2 = np.hstack((ones, z2))\n",
    "    d2 = np.multiply(initt_wt2.T @ d3[1:], SIGGrad(z2).T)\n",
    "    \n",
    "    \n",
    "    Delta1 = np.zeros(initt_wt1.shape)\n",
    "    Delta2 = np.zeros(initt_wt2.shape)\n",
    "    Delta3 = np.zeros(initt_wt3.shape)\n",
    "    Delta4 = np.zeros(initt_wt4.shape)\n",
    "\n",
    "   \n",
    "    Delta1 = Delta1 + d2[1:,:] @ a1\n",
    "    #print('Delta1',Delta1.shape)\n",
    "    Delta2 = Delta2 + d3[1:,:] @ a2\n",
    "    #print('Delta2',Delta2.shape)\n",
    "    Delta3 = Delta3 + d4[1:,:] @ a3\n",
    "    #print('Delta3',Delta3.shape)\n",
    "    Delta4 = Delta4 + d5.T @ a4\n",
    "    #print('Delta4',Delta4.shape)\n",
    "\n",
    "\n",
    "\n",
    "    Delta1 /= l\n",
    "    Delta2 /= l\n",
    "    Delta3 /= l\n",
    "    Delta4 /= l\n",
    "    \n",
    "     \n",
    "    return np.hstack((Delta1.ravel(order='F'), Delta2.ravel(order='F'),Delta3.ravel(order='F'),Delta4.ravel(order='F'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bckprop_wts = NN(ttl_weits, ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "#bckprop_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_y(wt1, wt2, wt3,wt4,X, y):\n",
    "    l = len(y)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    \n",
    "    a1 = np.hstack((ones, X))\n",
    "    \n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    \n",
    "    a2 = np.hstack((ones, a2))\n",
    "    \n",
    "    a3 = SIG(a2 @ wt2.T)\n",
    "    \n",
    "    a3 = np.hstack((ones, a3))\n",
    "    \n",
    "    a4 = SIG(a3 @ wt3.T)\n",
    "    \n",
    "    a4 = np.hstack((ones, a4))\n",
    "    \n",
    "    h = SIG(a4 @ wt4.T)\n",
    "    return  np.argmax(h, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Gard_checking(ttl_weits,bckprop_wts,ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls,X,y):\n",
    "    eps = 0.22\n",
    "   \n",
    "    \n",
    "    for i in range(5):\n",
    "        iterattion = int(np.random.rand()*len(ttl_weits))\n",
    "        #print('iterattion',iterattion)\n",
    "        adding_eps = np.zeros((len(ttl_weits),1))\n",
    "        #print('adding_eps',adding_eps)\n",
    "        adding_eps[iterattion] = eps\n",
    "        #print('adding_eps[iterattion]',adding_eps[iterattion])\n",
    "\n",
    "        ThetaPlus = Feedfrwd(ttl_weits + adding_eps.flatten(),ip_lyr,  hd_lyr1,hd_lyr2,hd_lyr3, no_labls,X,y)\n",
    "        \n",
    "        #print('ThetaPlus',ThetaPlus)\n",
    "        \n",
    "        ThetaMinus  = Feedfrwd(ttl_weits - adding_eps.flatten(),ip_lyr,  hd_lyr1,hd_lyr2,hd_lyr3, no_labls,X,y)\n",
    "        #print('ThetaMinus',ThetaMinus)\n",
    "        \n",
    "        num_app = (ThetaPlus - ThetaMinus) / float(2*eps)\n",
    "        print('num_app',num_app)\n",
    "       \n",
    "        print('bckprop_wts[iterattion]',bckprop_wts[iterattion])\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_app 0.11655921836889259\n",
      "bckprop_wts[iterattion] 0.11649404433887929\n",
      "num_app 0.020540900588218346\n",
      "bckprop_wts[iterattion] 0.02047736608068702\n",
      "num_app 0.014534364154489781\n",
      "bckprop_wts[iterattion] 0.01458982001181421\n",
      "num_app 0.0029938962287514377\n",
      "bckprop_wts[iterattion] 0.0030038081488430054\n",
      "num_app 0.014534364154489781\n",
      "bckprop_wts[iterattion] 0.01458982001181421\n"
     ]
    }
   ],
   "source": [
    "grad_chk=Gard_checking(ttl_weits,bckprop_wts,ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "\n",
    "grad_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.655273\n",
      "         Iterations: 50\n",
      "         Function evaluations: 124\n",
      "         Gradient evaluations: 124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -4.45881264, -18.75119976, -23.31902912,   0.2639022 ,\n",
       "       -11.55901642,  -0.800155  ,  -0.79904994,   8.97636911,\n",
       "       -12.86283229,   0.62673276,  -0.63481578,  -2.27900429,\n",
       "        -4.72729868,   1.83167115,   3.08473511,  -3.58754826,\n",
       "        -1.48704655,   1.58203055,  -1.87171016,   3.57113108,\n",
       "         2.44744005,  -5.86060519,  -2.49486387,   4.7190969 ,\n",
       "         0.67245368,  -6.36669558,  -3.96351877])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "Final_weights = opt.fmin_cg(maxiter = 50, f = Feedfrwd, x0 = ttl_weits, fprime = NN,\n",
    "                        args = (ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls,Train_ip,Train_otpts))\n",
    "\n",
    "Final_weights\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Final_wts1,Final_wts2,Final_wts3,Final_wts4 = Weights(Final_weights,ip_lyr, hd_lyr1,hd_lyr2,hd_lyr3, no_labls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting y values for test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predicting_y(Final_wts1,Final_wts2,Final_wts3,Final_wts4 ,X_test.iloc[:,:-1], y_test)\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual=X_test.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 7 1 0]\n",
      " [0 5 3 0]\n",
      " [0 1 5 0]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_actual,pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.3286749482401657\n",
      "precision_score 0.26421404682274247\n",
      "recall_score 0.43478260869565216\n",
      "AUC score : 0.7696078431372549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred, average=\"weighted\"))  \n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_actual,pred, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr, tpr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
