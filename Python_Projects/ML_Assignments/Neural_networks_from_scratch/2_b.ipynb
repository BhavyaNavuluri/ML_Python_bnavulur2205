{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_mcqs_avg_n20    False\n",
       "all_NBME_avg_n4     False\n",
       "CBSE_01             False\n",
       "CBSE_02             False\n",
       "LEVEL               False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  loading the data set \n",
    "file = pd.read_csv('BSOM_DataSet_for_HW3.csv')\n",
    "\n",
    "\n",
    "# to check whether there are any empty values or not \n",
    "df=file[['all_mcqs_avg_n20', 'all_NBME_avg_n4', 'CBSE_01',  'CBSE_02', 'LEVEL']]\n",
    "\n",
    "\n",
    "df['LEVEL'].fillna(value='A', inplace=True) \n",
    "\n",
    "df[['CBSE_02']].fillna(method ='bfill')\n",
    "#.fillna(52, inplace=True)\n",
    "df.fillna(df['CBSE_02'].mean(), inplace=True)\n",
    "\n",
    "df.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     all_mcqs_avg_n20  all_NBME_avg_n4  CBSE_01  CBSE_02  LEVEL\n",
      "0               0.736           0.7700       42     68.0      1\n",
      "1               0.740           0.8000       44     67.0      2\n",
      "2               0.807           0.8125       41     78.0      0\n",
      "3               0.886           0.9250       68     91.0      0\n",
      "4               0.839           0.8550       57     74.0      1\n",
      "..                ...              ...      ...      ...    ...\n",
      "110             0.637           0.6825       45     52.0      2\n",
      "111             0.751           0.8150       53     60.0      2\n",
      "112             0.811           0.8325       50     77.0      1\n",
      "113             0.729           0.7275       43     68.0      2\n",
      "114             0.839           0.8625       54     73.0      1\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "LEVEL = {'A': 0,'B': 1,'C':2,'D':3}\n",
    "\n",
    "df.LEVEL = [LEVEL[item] for item in df.LEVEL] \n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming y to binary number using one-hot- encoding\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#onhtencder = OneHotEncoder(categorical_features = [0]) \n",
    "\n",
    "onhtencder= ColumnTransformer([(\"LEVEL\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "\n",
    "data = onhtencder.fit_transform(df[['LEVEL']]).toarray() \n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df.iloc[:,:]\n",
    "\n",
    "X_norm = (X.iloc[:,:-1] - X.iloc[:,:-1].mean()) / (X.iloc[:,:-1].max() - X.iloc[:,:-1].min())\n",
    "\n",
    "\n",
    "\n",
    "X_modified = pd.concat([X_norm, X.iloc[:,-1]],axis=1)\n",
    "\n",
    "target=df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_modified, data, test_size=0.20,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Train_ip=np.array(X_train.iloc[:,:-1])\n",
    "Train_otpts=np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wt1 [[0 0 0 0 0]]\n",
      "wt2 [[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Initializing weights randomly\n",
    "\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "#wt1 is the weights from input layer to the hidden layer\n",
    "\n",
    "wt1 = np.zeros((1,5),dtype=int)\n",
    "\n",
    "#wt2 is the weights from hidden layer to the  onput layer\n",
    "\n",
    "wt2 = b = np.zeros((4,2),dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "ttl_weits = np.hstack((wt1.ravel(order='F'), wt2.ravel(order='F')))    \n",
    "\n",
    "# layers configuration \n",
    "\n",
    "ip_lyr = 4\n",
    "hd_lyr = 1\n",
    "no_labls = 4\n",
    "\n",
    "print('wt1',wt1)\n",
    "print('wt2',wt2)\n",
    "\n",
    "print(ttl_weits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weights(ttl_weits,ip,hidn,otpt):\n",
    "    w1 = np.reshape(ttl_weits[:hidn*(ip+1)], (hidn, ip+1), 'F')\n",
    "    w2 = np.reshape(ttl_weits[hidn*(ip+1):], (otpt, hidn+1), 'F')\n",
    "    return w1,w2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sigmoid  function \n",
    "def SIG(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "\n",
    "\n",
    "def SIGGrad(z):\n",
    "    return np.multiply(SIG(z), 1-SIG(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost(h,y):\n",
    "    cost = np.sum(np.multiply(y, np.log(h))+np.multiply(1-y, np.log(1-h)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y):\n",
    "    \n",
    "    wt1,wt2= Weights(ttl_weits, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    " \n",
    "    l = len(Train_otpts)\n",
    "   \n",
    "    ones = np.ones((l,1))\n",
    "    \n",
    "    a1 = np.hstack((ones, Train_ip))\n",
    "    \n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    \n",
    "    a2 = np.hstack((ones, a2))\n",
    "    \n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    \n",
    "    c = Cost(h,y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return c / (-l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_er = Feedfrwd(ttl_weits, ip_lyr, hd_lyr, no_labls, Train_ip,Train_otpts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(ttl_weits, ip_lyr, hd_lyr, no_labls, X, y):\n",
    "    \n",
    "    initt_wt1,initt_wt2= Weights(ttl_weits, ip_lyr, hd_lyr, no_labls)\n",
    "    \n",
    "    D1 = np.zeros(initt_wt1.shape)\n",
    "    D2 = np.zeros(initt_wt2.shape)\n",
    "    \n",
    "    l = len(y)\n",
    "\n",
    "    ones = np.ones((l,1))\n",
    "    \n",
    "    \n",
    "    a1 = np.hstack((ones, X))\n",
    "    z2 = a1 @ initt_wt1.T\n",
    "    a2 = np.hstack((ones, SIG(z2)))\n",
    "    z3 = a2 @ initt_wt2.T\n",
    "    a3 = SIG(z3)\n",
    "    \n",
    "    d3 = a3 - y\n",
    "    z2 = np.hstack((ones, z2))\n",
    "    d2 = np.multiply(initt_wt2.T @ d3.T, SIGGrad(z2).T)\n",
    "    D1 = D1 + d2[1:,:] @ a1\n",
    "    D2 = D2 + d3.T @ a2\n",
    "    \n",
    "   \n",
    "        \n",
    "    D1 /= l\n",
    "    D2 /= l\n",
    "    \n",
    "        \n",
    "    return np.hstack((D1.ravel(order='F'), D2.ravel(order='F')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bckprop_wts = NN(ttl_weits, ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting_y(wt1, wt2, X, y):\n",
    "    l = len(y)\n",
    "    ones = np.ones((l,1))\n",
    "    a1 = np.hstack((ones, X))\n",
    "    a2 = SIG(a1 @ wt1.T)\n",
    "    a2 = np.hstack((ones, a2))\n",
    "    h = SIG(a2 @ wt2.T)\n",
    "    return np.argmax(h, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Gard_checking(frwd_wts,bckprop_wts,iplyr, hdlyr, no_labls,Train_ip,Train_otpts):\n",
    "    eps = 0.22\n",
    "   \n",
    "    \n",
    "    for i in range(5):\n",
    "        iterattion = int(np.random.rand()*len(frwd_wts))\n",
    "        #print('iterattion',iterattion)\n",
    "        adding_eps = np.zeros((len(frwd_wts),1))\n",
    "        #print('adding_eps',adding_eps)\n",
    "        adding_eps[iterattion] = eps\n",
    "        #print('adding_eps[iterattion]',adding_eps[iterattion])\n",
    "\n",
    "        ThetaPlus = Feedfrwd(frwd_wts + adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts)\n",
    "        \n",
    "        #print('ThetaPlus',ThetaPlus)\n",
    "        \n",
    "        ThetaMinus  = Feedfrwd(frwd_wts - adding_eps.flatten(),iplyr, hdlyr, no_labls,Train_ip,Train_otpts)\n",
    "        #print('ThetaMinus',ThetaMinus)\n",
    "        \n",
    "        num_app = (ThetaPlus - ThetaMinus) / float(2*eps)\n",
    "        print('num_app',num_app)\n",
    "       \n",
    "        print('bckprop_wts[iterattion]',bckprop_wts[iterattion])\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_app 0.0\n",
      "bckprop_wts[iterattion] 0.0\n",
      "num_app 0.12500000000000036\n",
      "bckprop_wts[iterattion] 0.125\n",
      "num_app 0.0\n",
      "bckprop_wts[iterattion] 0.0\n",
      "num_app 0.12500000000000036\n",
      "bckprop_wts[iterattion] 0.125\n",
      "num_app 0.10869565217391494\n",
      "bckprop_wts[iterattion] 0.10869565217391304\n"
     ]
    }
   ],
   "source": [
    "grad_chk=Gard_checking(ttl_weits,bckprop_wts,ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts)\n",
    "\n",
    "\n",
    "grad_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.338862\n",
      "         Iterations: 50\n",
      "         Function evaluations: 149\n",
      "         Gradient evaluations: 149\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Final_wts = opt.fmin_cg(maxiter = 50, f = Feedfrwd, x0 = ttl_weits, fprime = NN,args = (ip_lyr, hd_lyr, no_labls,Train_ip,Train_otpts))\n",
    "\n",
    "\n",
    "Final_wts1,Final_wts2= Weights(Final_wts, ip_lyr, hd_lyr, no_labls)\n",
    "\n",
    "pred= predicting_y(Final_wts1, Final_wts2, X_test.iloc[:,:-1], y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 0 0]\n",
      " [4 6 0 0]\n",
      " [0 7 0 0]\n",
      " [0 2 0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_actual=X_test.iloc[:,-1]\n",
    "y_actual=np.array(y_actual)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_actual,pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score 0.22498274672187718\n",
      "precision_score 0.1797101449275362\n",
      "recall_score 0.30434782608695654\n",
      "AUC score : 0.65625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "print('f1_score',f1_score(y_actual,pred, average=\"weighted\"))\n",
    "print('precision_score',precision_score(y_actual,pred, average=\"weighted\"))\n",
    "print('recall_score',recall_score(y_actual,pred, average=\"weighted\"))  \n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_actual,pred, pos_label=2)\n",
    "print('AUC score :',metrics.auc(fpr, tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
