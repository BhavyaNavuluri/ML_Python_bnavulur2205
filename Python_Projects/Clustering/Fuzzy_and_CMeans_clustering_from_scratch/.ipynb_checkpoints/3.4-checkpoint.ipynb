{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from random import *\n",
    "\n",
    "import math\n",
    "# Importing the dataset\n",
    "\n",
    "#http://eneskemalergin.github.io/blog//blog/Fuzzy_Clustering/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115, 5)\n",
      "(115, 5)\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv('BSOM_DataSet_reorganized.csv')\n",
    "data=file[['all_NBME_avg_n4', 'all_PIs_avg_n131', 'HD_final','all_irats_avg_n34','HA_final']]\n",
    "\n",
    "X=np.array(data)\n",
    "print(data.shape)\n",
    "data.head()\n",
    "\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "# Number of Clusters\n",
    "clusters = 5\n",
    "\n",
    "\n",
    "# Number of data points\n",
    "n = len(data)\n",
    "print(n)\n",
    "\n",
    "\n",
    "# Fuzzy parameter\n",
    "fuzzifier = 2.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.92453308, 0.8288827 , 0.94846136, 0.91170583, 0.45182925]), array([0.7607797 , 0.86667182, 0.74652967, 0.84411694, 0.91402517]), array([0.90331251, 0.83339463, 0.99085398, 0.8338842 , 0.96062353]))\n",
      "Centroids [0.92453308 0.8288827  0.94846136 0.91170583 0.45182925]\n"
     ]
    }
   ],
   "source": [
    "# random centroids generation\n",
    "C0 = np.random.uniform(0.4,1.0,size=clusters)\n",
    "C1 = np.random.uniform(0.6,1.0,size=clusters)\n",
    "C2 = np.random.uniform(0.7,1.0,size=clusters)\n",
    "\n",
    "Centroids = C0,C1,C2\n",
    "print(Centroids)\n",
    "#Centroids=np.array(data.sample(3))\n",
    "print('Centroids',Centroids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance Caculator\n",
    "# Euclidean Distance Caculator\n",
    "\n",
    "def dist(a,b):\n",
    "        sum = 0\n",
    "        for m in range(len(a)):\n",
    "            for n in range(len(b)):\n",
    "\n",
    "                sum  += ((a[m][n] - b[m][n]))**2\n",
    "\n",
    "        ed = math.sqrt(sum)\n",
    "        return ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2876887410346424"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx=dist(X[[0]],Centroids[[0]])\n",
    "cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euc_dist(a, b, ax=1):\n",
    "    return np.linalg.norm(a - b, axis=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (230,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-205a3c7b5709>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m# n = num of data points\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mproduct_c0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mproduct_c0_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduct_c0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m#print('product_c0_df',product_c0_df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (230,) (5,) "
     ]
    }
   ],
   "source": [
    "while (error > 0.3):\n",
    "    \n",
    "    for i in range(n):\n",
    "        weights=[]# weights of points for all the clusters \n",
    "        for w in range(3):\n",
    "            w0=(euc_dist(X[[i]],Centroids[w])/euc_dist(X[[i]],Centroids[0]))**fuzzifier\n",
    "            #print('w0',w0)\n",
    "\n",
    "            w1=(euc_dist(X[[i]],Centroids[w])/euc_dist(X[[i]],Centroids[1]))**fuzzifier\n",
    "            #print('w1',w1)\n",
    "            w2=(euc_dist(X[[i]],Centroids[w])/euc_dist(X[[i]],Centroids[2]))**fuzzifier\n",
    "            #w3=(dist(X[[i]],Centroids[[w]])/dist(X[[i]],Centroids[[3]]))**fuzzifier\n",
    "            #print('w2',w2)\n",
    "            sum_val=w0+w1+w2\n",
    "                #print('sum_val',sum_val)\n",
    "\n",
    "                #print('sqr_sum',sqr_sum)\n",
    "            finl_weights=1/sum_val\n",
    "                #print('finl_weights',finl_weights)\n",
    "            #total_weights.append(finl_weights)\n",
    "            weights.append(finl_weights)\n",
    "        total_weights.append(weights)\n",
    "    #weights1_df=pd.DataFrame(total_weights)\n",
    "        \n",
    "        #print('total_weights',total_weights)\n",
    "\n",
    "    weights_df=pd.DataFrame(total_weights)\n",
    "    #print('weights_df',weights_df)\n",
    "\n",
    "    \n",
    "\n",
    "    #weights_df[0] = weights_df[0].str.get(0)\n",
    "    #weights_df[1] = weights_df[1].str.get(0)\n",
    "    #weights_df[2] = weights_df[2].str.get(0)\n",
    "\n",
    "\n",
    "    for l in range(clusters):\n",
    "        for v in range(n):# n = num of data points\n",
    "            product_c0=np.array(weights_df[l])*np.array(weights_df[l])*X[v]\n",
    "        product_c0_df=pd.DataFrame(product_c0)\n",
    "        #print('product_c0_df',product_c0_df)\n",
    "        productSum_df_c0=np.array(product_c0_df.sum(axis = 0))/np.sum(weights_df[l])\n",
    "        print('productSum_df_c0',productSum_df_c0)\n",
    "        #c_updated.append(productSum_df_c0)\n",
    "        if l==0:\n",
    "            c0=productSum_df_c0\n",
    "        if l==1:\n",
    "            c1=productSum_df_c0\n",
    "        if l==2:\n",
    "            c2=productSum_df_c0\n",
    "    c_updated =[c0,c1,c2] \n",
    "    #np.array(list(zip(c0,c1,c2)))\n",
    "    \n",
    "    \n",
    "    error = dist(c_old,c_updated)\n",
    "    c_old = c_updated\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(c_old)\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_labels=[]\n",
    "for i in range(len(weights_df)):\n",
    "    labels_val= np.argmax(np.array(weights_df.iloc[i,:]))\n",
    "    clust_labels.append(labels_val)\n",
    "weights_df['Labels']=clust_labels  \n",
    "\n",
    "print(weights_df['Labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(weights_df)\n",
    "points_list0=[]\n",
    "points_list1=[]\n",
    "points_list2=[]\n",
    "\n",
    "for i in range(len(weights_df[:-115])):\n",
    "    if (weights_df.iloc[i,-1]==0):\n",
    "        points_list0.append(X[i])\n",
    "    if (weights_df.iloc[i,-1]==1):\n",
    "        points_list1.append(X[i])\n",
    "    if (weights_df.iloc[i,-1]==2):\n",
    "        points_list2.append(X[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_list3=[]\n",
    "points_list3.append(points_list0 )\n",
    "points_list3.append(points_list1 )\n",
    "points_list3.append(points_list2 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#------------------------- For k=3 DB index values------------------------\n",
    "\n",
    "\n",
    "\n",
    "Si3_dist=[i for i in range(len(points_list3))]\n",
    "\n",
    "Si3_final=[]\n",
    "\n",
    "\n",
    "          \n",
    "for each in range(len(points_list3)):\n",
    "    #print(each)\n",
    "    \n",
    "    for si in points_list3[each]:\n",
    "        \n",
    "        Si3=euc_dist(si, c_updated[[each]]) \n",
    "        \n",
    "        Si3_dist.append(Si3)\n",
    "        #print(Si3_dist)\n",
    "    Si3_= (1/len(points_list3[each]))*np.sum(Si3_dist)\n",
    "    \n",
    "    Si3_final.append(Si3_)\n",
    "\n",
    "#print('Si3_dist',Si3_dist)\n",
    "#print('Si3_final',Si3_final)   \n",
    " \n",
    "\n",
    "C3_12=euc_dist(c_updated[[0]],c_updated[[1]])\n",
    "#print('C3_12',C3_12)\n",
    "C3_13=euc_dist(c_updated[[0]],c_updated[[2]])\n",
    "#print('C3_13',C3_13)\n",
    "C3_23=euc_dist(c_updated[[1]],c_updated[[2]])\n",
    "#print('C3_23',C3_23)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R3_12= (Si3_final[0]+Si3_final[1])/C3_12 #(S_i+S_j)/M_ij\n",
    "R3_13= (Si3_final[0]+Si3_final[2])/C3_13 #(S_i+S_j)/M_ij\n",
    "R3_23= (Si3_final[1]+Si3_final[2])/C3_13 #(S_i+S_j)/M_ij\n",
    "\n",
    "max_C3_R1=max(R3_12,R3_13)\n",
    "max_C3_R2=max(R3_12,R3_23)\n",
    "max_C3_R3=max(R3_13,R3_23)\n",
    "\n",
    "\n",
    "D3_i=max(max_C3_R1,max_C3_R2,max_C3_R3)\n",
    "\n",
    "\n",
    "\n",
    "DB_3=(1/3)*(D3_i)\n",
    "        \n",
    "print('DB value for k=3 with 3 features by using Fuzzy logic  is ',DB_3) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
